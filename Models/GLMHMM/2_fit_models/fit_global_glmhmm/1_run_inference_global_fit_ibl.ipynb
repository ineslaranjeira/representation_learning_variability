{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference global fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "IMPORTS\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import autograd.numpy as np\n",
    "from glm_hmm_utils import load_cluster_arr, load_session_fold_lookup, \\\n",
    "    load_data, create_violation_mask, launch_glm_hmm_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "PARAMETERS\n",
    "\"\"\"\n",
    "D = 1  # data (observations) dimension\n",
    "C = 2  # number of output types/categories\n",
    "N_em_iters = 300  # number of EM iterations\n",
    "\n",
    "USE_CLUSTER = False\n",
    "\n",
    "num_folds = 5\n",
    "global_fit = True\n",
    "# perform mle => set transition_alpha to 1\n",
    "transition_alpha = 1\n",
    "prior_sigma = 100\n",
    "\n",
    "bin_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIRECTORIES\n",
    "\"\"\"\n",
    "data_dir = '../../data/ibl/data_for_cluster/'\n",
    "data_dir = '/home/ines/repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "#data_dir = '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "\n",
    "\"\"\"\n",
    "Create folders to save processed data\n",
    "\"\"\"\n",
    "# Create directories for saving data:\n",
    "processed_ibl_data_path = data_dir + \"data_for_cluster/\" + \"data_by_bin\" + str(bin_num) + \"global_normalization/\"\n",
    "\n",
    "# Create directory for results:\n",
    "results_dir = '../../results/ibl_global_fit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  In order to facilitate parallelization of jobs, create a job array that\n",
    "#  can be used on e.g. a cluster\n",
    "import numpy as np\n",
    "\n",
    "K_vals = [2, 3, 4, 5]\n",
    "K_vals = [3]\n",
    "num_folds = 5\n",
    "N_initializations = 10\n",
    "\n",
    "cluster_job_arr = []\n",
    "for K in K_vals:\n",
    "    for i in range(num_folds):\n",
    "        for j in range(N_initializations):\n",
    "            cluster_job_arr.append([K, i, j])\n",
    "np.savez(processed_ibl_data_path + 'cluster_job_arr.npz',\n",
    "            cluster_job_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference with K = 3; Fold = 0; Iter = 0\n",
      "=== fitting GLM-HMM ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a5983917cf4bc58e4a8f4bf7e14049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if USE_CLUSTER:\n",
    "    z = int(sys.argv[1])\n",
    "else:\n",
    "    z = 0\n",
    "        \n",
    "# Load external files:\n",
    "cluster_arr_file = processed_ibl_data_path + 'cluster_job_arr.npz'\n",
    "# Load cluster array job parameters:\n",
    "cluster_arr = load_cluster_arr(cluster_arr_file)\n",
    "\n",
    "\n",
    "[K, fold, iter] = cluster_arr[z]\n",
    "\n",
    "\n",
    "# Get all data\n",
    "\n",
    "animal_file = processed_ibl_data_path + 'all_animals_concat.npz'\n",
    "inpt, y, bin_data = load_data(animal_file)\n",
    "bin_fold_lookup_table = load_session_fold_lookup(\n",
    "    processed_ibl_data_path + 'all_animals_concat_session_fold_lookup.npz')\n",
    "\n",
    "bin_values = np.unique(bin_data)\n",
    "bin_values = [0, 5, 9]\n",
    "# Loop through bins and fit a separate global GLM for each bin\n",
    "for b, bin in enumerate(bin_values):\n",
    "    \n",
    "    for m, model in enumerate(range(len(cluster_arr))):\n",
    "        \n",
    "        [K, fold, iter] = cluster_arr[m]\n",
    "            \n",
    "        # Subset of trials of interest for bin\n",
    "        bin_idx = np.where(bin_data == bin)\n",
    "        bin_y = y[bin_idx]\n",
    "        bin_bin_fold_lookup_table = bin_fold_lookup_table[bin_idx]\n",
    "        bin_inpt = inpt[bin_idx]\n",
    "        bin_bin_data = bin_data[bin_idx]  \n",
    "\n",
    "        #  append a column of ones to inpt to represent the bias covariate:\n",
    "        bin_inpt = np.hstack((bin_inpt, np.ones((len(bin_inpt),1))))\n",
    "        bin_y = bin_y.astype('int')\n",
    "        # Identify violations for exclusion:\n",
    "        violation_idx = np.where(bin_y == -1)[0]\n",
    "        nonviolation_idx, mask = create_violation_mask(violation_idx,\n",
    "                                                        bin_inpt.shape[0])\n",
    "\n",
    "        #  GLM weights to use to initialize GLM-HMM\n",
    "        init_param_file = results_dir + 'GLM/bin_' + str(bin+1) + '_fold_' + str(\n",
    "            fold) + '/variables_of_interest_iter_0.npz'\n",
    "\n",
    "        # create save directory for this initialization/fold combination:\n",
    "        save_directory = results_dir + '/GLM_HMM_K_' + str(\n",
    "            K) + '/bin_' + str(bin+1) + '/fold_' + str(fold) + '/' \n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "\n",
    "        launch_glm_hmm_job(bin_inpt,\n",
    "                            bin_y,\n",
    "                            bin_bin_data,\n",
    "                            mask,\n",
    "                            bin_bin_fold_lookup_table,\n",
    "                            K,\n",
    "                            D,\n",
    "                            C,\n",
    "                            N_em_iters,\n",
    "                            transition_alpha,\n",
    "                            prior_sigma,\n",
    "                            fold,\n",
    "                            iter,\n",
    "                            global_fit,\n",
    "                            init_param_file,\n",
    "                            save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f853f8609685127ea8e72dcad05addc0055bbd53b34efe8106300d089c6b555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
