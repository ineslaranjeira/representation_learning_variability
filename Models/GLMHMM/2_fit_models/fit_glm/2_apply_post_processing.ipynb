{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of size num_models x num_folds containing normalized loglikelihood for both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from post_processing_utils import load_data, load_session_fold_lookup, \\\n",
    "    prepare_data_for_cv, calculate_baseline_test_ll, \\\n",
    "    calculate_glm_test_loglikelihood, calculate_cv_bit_trial, \\\n",
    "    return_glmhmm_nll, return_lapse_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "# Parameters\n",
    "C = 2  # number of output classes\n",
    "num_folds = 5  # number of folds\n",
    "D = 1  # number of output dimensions\n",
    "K_max = 5  # maximum number of latent states\n",
    "num_models = K_max + 2  # model for each latent + 2 lapse models\n",
    "bin_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIRECTORIES\n",
    "\"\"\"\n",
    "data_dir = '../../data/ibl/data_for_cluster/'\n",
    "data_dir = '/home/ines/repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "data_dir = '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "\n",
    "\"\"\"\n",
    "Create folders to save processed data\n",
    "\"\"\"\n",
    "# Create directories for saving data:\n",
    "processed_ibl_data_path = data_dir + \"data_for_cluster/\" + \"data_by_bin\" + str(bin_num) + \"global_normalization/\"\n",
    "\n",
    "# Create directory for results:\n",
    "results_dir = '../../results/ibl_global_fit/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = GLM\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../results/ibl_global_fit//GLM/fold_0/variables_of_interest_iter_0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nt/d2j3zp9d1xzb8wgfrw81j0c40000gn/T/ipykernel_27686/2553516375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             ll_glm = calculate_glm_test_loglikelihood(\n\u001b[1;32m     40\u001b[0m                 \u001b[0mglm_weights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_nonviolation_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 test_inpt[0, test_nonviolation_mask == 1], M, C)\n\u001b[0m\u001b[1;32m     42\u001b[0m             ll_glm_train = calculate_glm_test_loglikelihood(\n\u001b[1;32m     43\u001b[0m                 \u001b[0mglm_weights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_nonviolation_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/representation_learning_variability/Models/GLMHMM/2_fit_models/fit_glm/post_processing_utils.py\u001b[0m in \u001b[0;36mcalculate_glm_test_loglikelihood\u001b[0;34m(glm_weights_file, test_y, test_inpt, M, C)\u001b[0m\n\u001b[1;32m    226\u001b[0m def calculate_glm_test_loglikelihood(glm_weights_file, test_y, test_inpt, M,\n\u001b[1;32m    227\u001b[0m                                      C):\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mloglikelihood_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglm_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_glm_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglm_weights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Calculate test loglikelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mnew_glm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Repositories/representation_learning_variability/Models/GLMHMM/2_fit_models/fit_glm/post_processing_utils.py\u001b[0m in \u001b[0;36mload_glm_vectors\u001b[0;34m(glm_vectors_file)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_glm_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglm_vectors_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglm_vectors_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mloglikelihood_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/glmhmm/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../results/ibl_global_fit//GLM/fold_0/variables_of_interest_iter_0.npz'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "inpt, y, bin_data = load_data(processed_ibl_data_path + 'all_animals_concat.npz')\n",
    "bin_fold_lookup_table = load_session_fold_lookup(\n",
    "    processed_ibl_data_path + 'all_animals_concat_session_fold_lookup.npz')\n",
    "\n",
    "# For later saving the data\n",
    "animal_preferred_model_dict = {}\n",
    "models = [\"GLM\", \"Lapse_Model\", \"GLM_HMM\"]\n",
    "\n",
    "cvbt_folds_model = np.zeros((num_models, num_folds))\n",
    "cvbt_train_folds_model = np.zeros((num_models, num_folds))\n",
    "\n",
    "# Save best initialization for each model-fold combination\n",
    "best_init_cvbt_dict = {}\n",
    "for fold in range(num_folds):\n",
    "    test_inpt, test_y, test_nonviolation_mask, this_test_session, \\\n",
    "    train_inpt, train_y, train_nonviolation_mask, this_train_session, M,\\\n",
    "    n_test, n_train = prepare_data_for_cv(\n",
    "        inpt, y, bin_data, bin_fold_lookup_table, fold)\n",
    "    \n",
    "    \n",
    "    # Ines addapted\n",
    "    ll0 = calculate_baseline_test_ll(\n",
    "        train_y[0, train_nonviolation_mask == 1],\n",
    "        test_y[0, test_nonviolation_mask == 1], C)\n",
    "    ll0_train = calculate_baseline_test_ll(\n",
    "        train_y[0, train_nonviolation_mask == 1],\n",
    "        train_y[0, train_nonviolation_mask == 1], C)\n",
    "\n",
    "    for model in models:\n",
    "        print(\"model = \" + str(model))\n",
    "        if model == \"GLM\":\n",
    "            # Load parameters and instantiate a new GLM object with\n",
    "            # these parameters\n",
    "            glm_weights_file = results_dir + '/GLM/fold_' + str(\n",
    "                fold) + '/variables_of_interest_iter_0.npz'\n",
    "            \n",
    "            # Ines addapted, because data is in a different format\n",
    "            ll_glm = calculate_glm_test_loglikelihood(\n",
    "                glm_weights_file, test_y[0, test_nonviolation_mask == 1],\n",
    "                test_inpt[0, test_nonviolation_mask == 1], M, C)\n",
    "            ll_glm_train = calculate_glm_test_loglikelihood(\n",
    "                glm_weights_file, train_y[0, train_nonviolation_mask == 1],\n",
    "                train_inpt[0, train_nonviolation_mask == 1], M, C)\n",
    "            \n",
    "            cvbt_folds_model[0, fold] = calculate_cv_bit_trial(\n",
    "                ll_glm, ll0, n_test)\n",
    "            cvbt_train_folds_model[0, fold] = calculate_cv_bit_trial(\n",
    "                ll_glm_train, ll0_train, n_train)\n",
    "            \n",
    "# Save cvbt_folds_model as numpy array for easy parsing across all\n",
    "# models and folds\n",
    "np.savez(results_dir + \"/cvbt_folds_model.npz\", cvbt_folds_model)\n",
    "np.savez(results_dir + \"/cvbt_train_folds_model.npz\",\n",
    "            cvbt_train_folds_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glmhmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0570267f7605a5796a6c6283f704801f1f25a3a6f849e378a7aefdb53302a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
