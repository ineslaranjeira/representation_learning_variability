{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit GLM per animal per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glm_utils import load_session_fold_lookup, load_data, load_animal_list, \\\n",
    "    fit_glm, plot_input_vectors, append_zeros, calculate_predictive_acc_glm\n",
    "\n",
    "npr.seed(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some parameters\n",
    "\"\"\"\n",
    "C = 2  # number of output types/categories\n",
    "N_initializations = 10\n",
    "num_folds = 5\n",
    "num_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "\"\"\"\n",
    "data_dir = '/home/ines/repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "#data_dir = '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "\n",
    "processed_ibl_data_path = data_dir + \"data_for_cluster/\" + \"data_by_bin\" + str(num_bins) + \"global_normalization/\"\n",
    "# Load animal list/results of partial processing:\n",
    "animal_list = load_animal_list(\n",
    "    data_dir + 'animal_list.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create directory for saving results\n",
    "\"\"\"\n",
    "results_dir = '../../results/ibl_individual_fit/' + str(num_bins) + \"global_normalization/\" \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCLA0151\n",
      "UCLA0041\n",
      "KS0561\n",
      "ibl_witten_271\n",
      "NYU-111\n",
      "LTC031\n",
      "UCLA0152\n",
      "UCLA0092\n",
      "DY_0172\n",
      "NYU-112\n",
      "UCLA0043\n",
      "DY_0173\n",
      "DY_0083\n",
      "UCLA0044\n",
      "DY_0084\n",
      "DY_0085\n",
      "DY_0086\n",
      "ZFM-052347\n",
      "DY_0198\n",
      "DY_0088\n",
      "DY_0199\n",
      "DY_0089\n",
      "UCLA00910\n",
      "DY_01910\n"
     ]
    }
   ],
   "source": [
    "# Loop through bins\n",
    "for b, bin in enumerate(range(num_bins)):\n",
    "    #animal_list = load_animal_list(\n",
    "    #processed_ibl_data_path + 'animal_list_bin_' + str(bin+1) +'.npz')\n",
    "    animal_list = load_animal_list(\n",
    "    processed_ibl_data_path + 'animal_list.npz')\n",
    "    \n",
    "    # Loop through animals in the bin\n",
    "    for a, animal in enumerate(animal_list):\n",
    "        # Fit GLM to data from single animal:\n",
    "        animal_file = processed_ibl_data_path + animal + '_bin_' + str(bin+1) + '_processed.npz'\n",
    "        if os.path.exists(animal_file):\n",
    "            \n",
    "            bin_fold_lookup_table = load_session_fold_lookup(\n",
    "                processed_ibl_data_path + animal + '_' + str(bin+1)+ '_bin_fold_lookup.npz')\n",
    "\n",
    "            unnormalized_data = processed_ibl_data_path + animal + '_' + str(bin+1) + '_unnormalized.npz'\n",
    "            \n",
    "            \"\"\"\n",
    "            # Check psychometric curves!\n",
    "            un_inpt, un_y, un_bin_data = load_data(unnormalized_data)\n",
    "            plt.figure()\n",
    "            x_stim = np.unique(un_inpt[:, 0])\n",
    "            y_stim = np.zeros(len(x_stim))\n",
    "            \n",
    "            for s, stimulus in enumerate(x_stim):\n",
    "                y_stim[s] = np.nanmean(un_y[np.where(un_inpt[:, 0]==stimulus), 0])\n",
    "            plt.scatter(x_stim, y_stim)\n",
    "            plt.title('Bin' + str(bin+1))\n",
    "            plt.ylim([0,1])\n",
    "            \"\"\"    \n",
    "            for fold in range(num_folds):\n",
    "                this_results_dir = results_dir + animal + '_' + str(bin+1) + '/'\n",
    "\n",
    "                # Load data\n",
    "                inpt, y, bin_data = load_data(animal_file)\n",
    "                labels_for_plot = ['stim', 'pc', 'wsls', 'bias']\n",
    "                y = y.astype('int')\n",
    "\n",
    "                figure_directory = this_results_dir + \"GLM/fold_\" + str(fold) + '/'\n",
    "                if not os.path.exists(figure_directory):\n",
    "                    os.makedirs(figure_directory)\n",
    "\n",
    "                # Subset to trials of interest for fold\n",
    "\n",
    "                trials_idx = np.arange(len(y))\n",
    "                keep_fold = trials_idx[\n",
    "                    np.where(bin_fold_lookup_table != fold)]  # TODO: what is y == -1?\n",
    "\n",
    "                keep_y = [y[id, 0] != -1\n",
    "                    for id, binn in enumerate(trials_idx)]\n",
    "                keep_y = trials_idx[keep_y]\n",
    "                idx_to_keep = np.sort(np.intersect1d(keep_y, keep_fold))\n",
    "                idx_this_fold = trials_idx[idx_to_keep]\n",
    "                \n",
    "                this_inpt, this_y, this_session = inpt[idx_this_fold, :], \\\n",
    "                                                    y[idx_this_fold, :], \\\n",
    "                                                    bin_data[idx_this_fold]\n",
    "                \n",
    "                # Subset to trials for calculation of predictive accuracy\n",
    "                # TODO\n",
    "                left_out_fold = trials_idx[\n",
    "                    np.where(bin_fold_lookup_table == fold)]  \n",
    "                \n",
    "                if len(np.unique(this_y)) == 2:\n",
    "                    \n",
    "                    # This assertion is redundant\n",
    "                    assert len(\n",
    "                        np.unique(this_y)\n",
    "                    ) == 2, \"choice vector should only include 2 possible values\"\n",
    "                    \n",
    "                    train_size = this_inpt.shape[0]\n",
    "\n",
    "                    M = this_inpt.shape[1]\n",
    "                    loglikelihood_train_vector = []\n",
    "                    pred_acc_vector = []\n",
    "\n",
    "                    for iter in range(N_initializations):\n",
    "                        loglikelihood_train, recovered_weights = fit_glm([this_inpt],\n",
    "                                                                            [this_y], M,\n",
    "                                                                            C)\n",
    "                        weights_for_plotting = append_zeros(recovered_weights)\n",
    "                        # Calculate predictive accuracy based on left out fold \n",
    "                        predictive_acc = calculate_predictive_acc_glm(recovered_weights, inpt, y, left_out_fold)\n",
    "                        \n",
    "                        \"\"\"\n",
    "                        if iter == 0 and fold == 0:\n",
    "                            plot_input_vectors(weights_for_plotting,\n",
    "                                                figure_directory,\n",
    "                                                title=\"GLM fit; Final LL = \" +\n",
    "                                                str(loglikelihood_train) + \"Predictive acc =\" + str(predictive_acc),\n",
    "                                                save_title='init' + str(iter),\n",
    "                                                labels_for_plot=labels_for_plot)\n",
    "                        \"\"\"\n",
    "                        loglikelihood_train_vector.append(loglikelihood_train)\n",
    "                        pred_acc_vector.append(predictive_acc)\n",
    "                        \n",
    "                        # Save model results\n",
    "                        np.savez(\n",
    "                            figure_directory + 'variables_of_interest_iter_' +\n",
    "                            str(iter) + '.npz', loglikelihood_train, recovered_weights, predictive_acc)\n",
    "                        \n",
    "        else:\n",
    "            print(str(animal + str(bin+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glmhmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0570267f7605a5796a6c6283f704801f1f25a3a6f849e378a7aefdb53302a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
