{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of size num_models x num_folds containing normalized loglikelihood for both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from post_processing_utils import load_data, load_session_fold_lookup, \\\n",
    "    prepare_data_for_cv, calculate_baseline_test_ll, \\\n",
    "    calculate_glm_test_loglikelihood, calculate_cv_bit_trial, \\\n",
    "    return_glmhmm_nll, return_lapse_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "# Parameters\n",
    "C = 2  # number of output classes\n",
    "num_folds = 5  # number of folds\n",
    "D = 1  # number of output dimensions\n",
    "K_max = 5  # maximum number of latent states\n",
    "num_models = K_max + 2  # model for each latent + 2 lapse models\n",
    "bin_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIRECTORIES\n",
    "\"\"\"\n",
    "data_dir = '../../data/ibl/data_for_cluster/'\n",
    "data_dir = '/home/ines/repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "#data_dir = '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/DATA/GLMHMM/'\n",
    "\n",
    "\"\"\"\n",
    "Create folders to save processed data\n",
    "\"\"\"\n",
    "# Create directories for saving data:\n",
    "processed_ibl_data_path = data_dir + \"data_for_cluster/\" + \"data_by_animal/\"\n",
    "\n",
    "# Create directory for results:\n",
    "results_dir = '../../../results/proficient/ibl_global_fit/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = GLM\n",
      "model = Lapse_Model\n",
      "model = GLM_HMM\n",
      "model = GLM\n",
      "model = Lapse_Model\n",
      "model = GLM_HMM\n",
      "model = GLM\n",
      "model = Lapse_Model\n",
      "model = GLM_HMM\n",
      "model = GLM\n",
      "model = Lapse_Model\n",
      "model = GLM_HMM\n",
      "model = GLM\n",
      "model = Lapse_Model\n",
      "model = GLM_HMM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "inpt, y, session = load_data(data_dir + \"data_for_cluster/\" + 'all_animals_concat.npz')\n",
    "session_fold_lookup_table = load_session_fold_lookup(\n",
    "    data_dir + \"data_for_cluster/\" + 'all_animals_concat_session_fold_lookup.npz')\n",
    "\n",
    "# For later saving the data\n",
    "animal_preferred_model_dict = {}\n",
    "models = [\"GLM\", \"Lapse_Model\", \"GLM_HMM\"]\n",
    "\n",
    "cvbt_folds_model = np.zeros((num_models, num_folds))\n",
    "cvbt_train_folds_model = np.zeros((num_models, num_folds))\n",
    "\n",
    "# Save best initialization for each model-fold combination\n",
    "best_init_cvbt_dict = {}\n",
    "for fold in range(num_folds):\n",
    "    test_inpt, test_y, test_nonviolation_mask, this_test_session, \\\n",
    "    train_inpt, train_y, train_nonviolation_mask, this_train_session, M,\\\n",
    "    n_test, n_train = prepare_data_for_cv(\n",
    "        inpt, y, session, session_fold_lookup_table, fold)\n",
    "    \n",
    "    ll0 = calculate_baseline_test_ll(\n",
    "        train_y[train_nonviolation_mask == 1, :],\n",
    "        test_y[test_nonviolation_mask == 1, :], C)\n",
    "    ll0_train = calculate_baseline_test_ll(\n",
    "        train_y[train_nonviolation_mask == 1, :],\n",
    "        train_y[train_nonviolation_mask == 1, :], C)\n",
    "        \n",
    "    for model in models:\n",
    "        print(\"model = \" + str(model))\n",
    "        if model == \"GLM\":\n",
    "            # Load parameters and instantiate a new GLM object with\n",
    "            # these parameters\n",
    "            glm_weights_file = results_dir + '/GLM/fold_' + str(\n",
    "                fold) + '/variables_of_interest_iter_0.npz'\n",
    "\n",
    "            ll_glm = calculate_glm_test_loglikelihood(\n",
    "                glm_weights_file, test_y[test_nonviolation_mask == 1, :],\n",
    "                test_inpt[test_nonviolation_mask == 1, :], M, C)\n",
    "            ll_glm_train = calculate_glm_test_loglikelihood(\n",
    "                glm_weights_file, train_y[train_nonviolation_mask == 1, :],\n",
    "                train_inpt[train_nonviolation_mask == 1, :], M, C)\n",
    "            cvbt_folds_model[0, fold] = calculate_cv_bit_trial(\n",
    "                ll_glm, ll0, n_test)\n",
    "            cvbt_train_folds_model[0, fold] = calculate_cv_bit_trial(\n",
    "                ll_glm_train, ll0_train, n_train)\n",
    "                \n",
    "# Save cvbt_folds_model as numpy array for easy parsing across all\n",
    "# models and folds\n",
    "np.savez(results_dir + \"/cvbt_folds_model.npz\", cvbt_folds_model)\n",
    "np.savez(results_dir + \"/cvbt_train_folds_model.npz\",\n",
    "            cvbt_train_folds_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glmhmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0570267f7605a5796a6c6283f704801f1f25a3a6f849e378a7aefdb53302a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
