{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor correlates of prior\n",
    "https://github.com/int-brain-lab/paper-brain-wide-map/blob/main/brainwidemap/meta/fig_motor_correlates_prior.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/miniconda3/envs/ibl_bwm/lib/python3.10/site-packages/ibllib/atlas/__init__.py:205: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This code produces panels related to the motor correlates block of the\n",
    "brain-wide-map paper. It references a npy file\n",
    "(15f742e1-1043-45c9-9504-f1e8a53c1744_left.npy) containing an\n",
    "example frame being used for illustration in one panel.\n",
    "This file is assumed to be in your current working directory when\n",
    "plotting the paw position on the example frame.\n",
    "\n",
    "Cutting 7 behaviors during the inter-trial interval for all BWM\n",
    "sessions takes about 1 h. One can use one core per lag variable\n",
    "and compute in parallel. The lag variable specifies the start of\n",
    "the inter-trial interval and we compute it for two lags.\n",
    "\n",
    "See the code in the if __name__ == \"__main__\" block of this script.\n",
    "'''\n",
    "\n",
    "from one.api import ONE\n",
    "import brainbox.behavior.wheel as wh\n",
    "from brainbox.processing import bincount2D\n",
    "from ibllib.atlas import AllenAtlas\n",
    "from ibllib.atlas.regions import BrainRegions\n",
    "from brainbox.io.one import SpikeSortingLoader\n",
    "from brainbox.io.one import SessionLoader\n",
    "from brainwidemap import bwm_query, load_trials_and_mask\n",
    "import ibllib\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "[Errno 400] https://openalyx.internationalbrainlab.org/auth-token: 'Alyx authentication failed with credentials: user = int-brain-lab, password = *************'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m mpl\u001b[39m.\u001b[39mrcParams\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mfont.size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m})\n\u001b[0;32m----> 3\u001b[0m one \u001b[39m=\u001b[39m ONE(base_url\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhttps://openalyx.internationalbrainlab.org\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m           password\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minternational\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# save results for plotting here\u001b[39;00m\n\u001b[1;32m      7\u001b[0m pth_res \u001b[39m=\u001b[39m Path(one\u001b[39m.\u001b[39mcache_dir, \u001b[39m'\u001b[39m\u001b[39mbrain_wide_map\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibl_bwm/lib/python3.10/site-packages/one/api.py:1466\u001b[0m, in \u001b[0;36mONE\u001b[0;34m(mode, wildcards, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlocal\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1464\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39many\u001b[39m(x \u001b[39min\u001b[39;00m kwargs \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mbase_url\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m         \u001b[39mnot\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcache_dir\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)):\n\u001b[0;32m-> 1466\u001b[0m     \u001b[39mreturn\u001b[39;00m OneAlyx(mode\u001b[39m=\u001b[39;49mmode, wildcards\u001b[39m=\u001b[39;49mwildcards, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1468\u001b[0m \u001b[39m# If cache dir was provided and corresponds to one configured with an Alyx client, use OneAlyx\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ibl_bwm/lib/python3.10/site-packages/one/api.py:1510\u001b[0m, in \u001b[0;36mOneAlyx.__init__\u001b[0;34m(self, username, password, base_url, cache_dir, mode, wildcards, tables_dir, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"An API for searching and loading data through the Alyx database\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \n\u001b[1;32m   1483\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39m    'GET'.  Use None to deactivate cache (not recommended).\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[39m# Load Alyx Web client\u001b[39;00m\n\u001b[0;32m-> 1510\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_web_client \u001b[39m=\u001b[39m wc\u001b[39m.\u001b[39;49mAlyxClient(username\u001b[39m=\u001b[39;49musername,\n\u001b[1;32m   1511\u001b[0m                                  password\u001b[39m=\u001b[39;49mpassword,\n\u001b[1;32m   1512\u001b[0m                                  base_url\u001b[39m=\u001b[39;49mbase_url,\n\u001b[1;32m   1513\u001b[0m                                  cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1514\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_endpoint \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msessions\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# get parameters override if inputs provided\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibl_bwm/lib/python3.10/site-packages/one/webclient.py:501\u001b[0m, in \u001b[0;36mAlyxClient.__init__\u001b[0;34m(self, base_url, username, password, cache_dir, silent, cache_rest)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_par \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_par\u001b[39m.\u001b[39mset(\u001b[39m'\u001b[39m\u001b[39mCACHE_DIR\u001b[39m\u001b[39m'\u001b[39m, cache_dir \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_par\u001b[39m.\u001b[39mCACHE_DIR)\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m username \u001b[39mor\u001b[39;00m password:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauthenticate(username, password)\n\u001b[1;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rest_schemes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39m# the mixed accept application may cause errors sometimes, only necessary for the docs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibl_bwm/lib/python3.10/site-packages/one/webclient.py:676\u001b[0m, in \u001b[0;36mAlyxClient.authenticate\u001b[0;34m(self, username, password, cache_token, force)\u001b[0m\n\u001b[1;32m    673\u001b[0m     redacted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(credentials[\u001b[39m'\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mif\u001b[39;00m credentials[\u001b[39m'\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     message \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mAlyx authentication failed with credentials: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    675\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39muser = \u001b[39m\u001b[39m{\u001b[39;00mcredentials[\u001b[39m\"\u001b[39m\u001b[39musername\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, password = \u001b[39m\u001b[39m{\u001b[39;00mredacted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 676\u001b[0m     \u001b[39mraise\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError(rep\u001b[39m.\u001b[39mstatus_code, rep\u001b[39m.\u001b[39murl, message, response\u001b[39m=\u001b[39mrep)\n\u001b[1;32m    677\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     rep\u001b[39m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mHTTPError\u001b[0m: [Errno 400] https://openalyx.internationalbrainlab.org/auth-token: 'Alyx authentication failed with credentials: user = int-brain-lab, password = *************'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mpl.rcParams.update({'font.size': 10})\n",
    "\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org',\n",
    "          password='international')\n",
    "\n",
    "# save results for plotting here\n",
    "pth_res = Path(one.cache_dir, 'brain_wide_map', 'meta')\n",
    "pth_res.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ba = AllenAtlas()\n",
    "br = BrainRegions()\n",
    "\n",
    "T_BIN = 0.02\n",
    "Fs = {'left': 60, 'right': 150, 'body': 30}\n",
    "\n",
    "# specify binning type, either bins or sampling rate; see cut_gahavior for defs\n",
    "sr = {'licking': 'T_BIN', 'whisking_l': 60, 'whisking_r': 150,\n",
    "      'wheeling': 'T_BIN', 'nose_pos': 60, 'paw_pos_r': 150,\n",
    "      'paw_pos_l': 60}\n",
    "\n",
    "blue_left = [0.13850039, 0.41331206, 0.74052025]\n",
    "red_right = [0.66080672, 0.21526712, 0.23069468]\n",
    "cdi = {0.8: blue_left, 0.2: red_right, 0.5: 'g', -1: 'cyan', 1: 'orange'}\n",
    "\n",
    "\n",
    "def get_allen_info():\n",
    "    '''\n",
    "    Function to load Allen region info, e.g. region colors palette\n",
    "    '''\n",
    "\n",
    "    p = (Path(ibllib.__file__).parent /\n",
    "         'atlas/allen_structure_tree.csv')\n",
    "\n",
    "    dfa = pd.read_csv(p)\n",
    "\n",
    "    # get colors per acronym and transfomr into RGB\n",
    "    dfa['color_hex_triplet'] = dfa['color_hex_triplet'].fillna('FFFFFF')\n",
    "    dfa['color_hex_triplet'] = dfa['color_hex_triplet'\n",
    "                                   ].replace('19399', '19399a')\n",
    "    dfa['color_hex_triplet'] = dfa['color_hex_triplet'] .replace('0', 'FFFFFF')\n",
    "    dfa['color_hex_triplet'] = '#' + dfa['color_hex_triplet'].astype(str)\n",
    "    dfa['color_hex_triplet'] = dfa['color_hex_triplet'\n",
    "                                   ].apply(lambda x:\n",
    "                                           mpl.colors.to_rgba(x))\n",
    "\n",
    "    palette = dict(zip(dfa.acronym, dfa.color_hex_triplet))\n",
    "\n",
    "    return dfa, palette\n",
    "\n",
    "\n",
    "def generate_pseudo_blocks(\n",
    "        n_trials,\n",
    "        factor=60,\n",
    "        min_=20,\n",
    "        max_=100,\n",
    "        first5050=90):\n",
    "    \"\"\"\n",
    "    Generate a pseudo block structure\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_trials : int\n",
    "        how many trials to generate\n",
    "    factor : int\n",
    "        factor of the exponential\n",
    "    min_ : int\n",
    "        minimum number of trials per block\n",
    "    max_ : int\n",
    "        maximum number of trials per block\n",
    "    first5050 : int\n",
    "        amount of trials with 50/50 left right probability at the beginning\n",
    "    Returns\n",
    "    ---------\n",
    "    probabilityLeft : 1D array\n",
    "        array with probability left per trial\n",
    "    \"\"\"\n",
    "\n",
    "    block_ids = []\n",
    "    while len(block_ids) < n_trials:\n",
    "        x = np.random.exponential(factor)\n",
    "        while (x <= min_) | (x >= max_):\n",
    "            x = np.random.exponential(factor)\n",
    "        if (len(block_ids) == 0) & (np.random.randint(2) == 0):\n",
    "            block_ids += [0.2] * int(x)\n",
    "        elif (len(block_ids) == 0):\n",
    "            block_ids += [0.8] * int(x)\n",
    "        elif block_ids[-1] == 0.2:\n",
    "            block_ids += [0.8] * int(x)\n",
    "        elif block_ids[-1] == 0.8:\n",
    "            block_ids += [0.2] * int(x)\n",
    "    return np.array([0.5] * first5050 + block_ids[:n_trials - first5050])\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    '''\n",
    "    Find the index of the array, such that the\n",
    "    value is closest to that\n",
    "    '''\n",
    "\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(\n",
    "            value - array[idx - 1]) < math.fabs(value - array[idx])):\n",
    "        return idx - 1\n",
    "    else:\n",
    "        return idx\n",
    "\n",
    "\n",
    "def get_licks(dlc):\n",
    "    '''\n",
    "    define a frame as a lick frame if\n",
    "    x or y for left or right tongue point\n",
    "    change more than half the sdt of the diff\n",
    "    '''\n",
    "\n",
    "    licks = []\n",
    "    for point in ['tongue_end_l', 'tongue_end_r']:\n",
    "        for co in ['x', 'y']:\n",
    "            c = dlc[point + '_' + co]\n",
    "            thr = np.nanstd(np.diff(c)) / 4\n",
    "            licks.append(set(np.where(abs(np.diff(c)) > thr)[0]))\n",
    "    return sorted(list(set.union(*licks)))\n",
    "\n",
    "\n",
    "def cut_behavior(eid, duration=0.4, lag=-0.6,\n",
    "                 align='stimOn_times', stim_to_stim=False,\n",
    "                 endTrial=False, query_type='remote', pawex=False):\n",
    "    '''\n",
    "    For a given session, cut segments of 7 behaviors\n",
    "\n",
    "    param: eid: session eid\n",
    "    param: align: in stimOn_times, firstMovement_times, feedback_times\n",
    "    param: lag: time in sec wrt to align time to start segment\n",
    "    param: duration: length of cut segment in sec\n",
    "    '''\n",
    "    sess_loader = SessionLoader(one, eid)\n",
    "\n",
    "    # get wheel speed\n",
    "    sess_loader.load_wheel()\n",
    "    wheel = sess_loader.wheel\n",
    "\n",
    "    # load whisker motion energy, separate for both cams\n",
    "    sess_loader.load_motion_energy(views=['left', 'right'])\n",
    "    left_whisker = sess_loader.motion_energy['leftCamera']\n",
    "    right_whisker = sess_loader.motion_energy['rightCamera']\n",
    "\n",
    "    # load DLC\n",
    "    sess_loader.load_pose(views=['left', 'right'])\n",
    "    dlc_left = sess_loader.pose['leftCamera']\n",
    "    dlc_right = sess_loader.pose['rightCamera']\n",
    "\n",
    "    # get licks using both cameras\n",
    "    lick_times = []\n",
    "    for dlc in [dlc_left, dlc_right]:\n",
    "        r = get_licks(dlc)\n",
    "        lick_times.append(dlc['times'][r])\n",
    "\n",
    "    # combine left/right video licks and bin\n",
    "    lick_times = sorted(np.concatenate(lick_times))\n",
    "    R, times_lick, _ = bincount2D(lick_times, np.ones(len(lick_times)), T_BIN)\n",
    "    lcs = R[0]\n",
    "\n",
    "    # get paw position, for each cam separate\n",
    "    if pawex:  # to illustrate paw position scatter on example frame\n",
    "        paw_pos_r0 = np.array(list(zip(dlc_right['paw_r_x'],\n",
    "                                       dlc_right['paw_r_y'])))\n",
    "        paw_pos_l0 = np.array(list(zip(dlc_left['paw_r_x'],\n",
    "                                       dlc_left['paw_r_y'])))\n",
    "    else:\n",
    "        paw_pos_r0 = (dlc_right['paw_r_x']**2 + dlc_right['paw_r_y']**2)**0.5\n",
    "        paw_pos_l0 = (dlc_left['paw_r_x']**2 + dlc_left['paw_r_y']**2)**0.5\n",
    "\n",
    "    ds = ('licking', 'whisking_l', 'whisking_r', 'wheeling',\n",
    "          'nose_pos', 'paw_pos_r', 'paw_pos_l',\n",
    "          'pleft', 'sides', 'choices', 'T')\n",
    "\n",
    "    D = dict(zip(ds, [[] for x in ds])) #\n",
    "\n",
    "    # continuous time series of behavior and stamps\n",
    "    behaves = {'licking': [times_lick, lcs],\n",
    "               'whisking_l': [left_whisker['times'],\n",
    "                              left_whisker['whiskerMotionEnergy']],\n",
    "               'whisking_r': [right_whisker['times'],\n",
    "                              right_whisker['whiskerMotionEnergy']],\n",
    "               'wheeling': [wheel['times'], abs(wheel['velocity'])],\n",
    "               'nose_pos': [dlc_left['times'], dlc_left['nose_tip_x']],\n",
    "               'paw_pos_r': [dlc_right['times'], paw_pos_r0],\n",
    "               'paw_pos_l': [dlc_left['times'], paw_pos_l0]}\n",
    "\n",
    "    trials, mask = load_trials_and_mask(one, eid)\n",
    "\n",
    "    kk = 0\n",
    "\n",
    "    for tr in range(1, len(trials) - 1):\n",
    "\n",
    "        if not mask[tr]:\n",
    "            continue\n",
    "        # skip block boundary trials\n",
    "        if trials['probabilityLeft'][tr] != trials['probabilityLeft'][tr + 1]:\n",
    "            continue\n",
    "\n",
    "        start_t = trials[align][tr] + lag\n",
    "\n",
    "        if np.isnan(trials['contrastLeft'][tr]):\n",
    "            side = 0  # right side stimulus\n",
    "        else:\n",
    "            side = 1  # left side stimulus\n",
    "\n",
    "        D['sides'].append(side)\n",
    "\n",
    "        if endTrial:\n",
    "            D['choices'].append(trials['choice'][tr + 1])\n",
    "        else:\n",
    "            D['choices'].append(trials['choice'][tr])\n",
    "\n",
    "        D['pleft'].append(trials['probabilityLeft'][tr])\n",
    "\n",
    "        for be in behaves:\n",
    "            times = behaves[be][0]\n",
    "            series = behaves[be][1]\n",
    "            start_idx = find_nearest(times, start_t)\n",
    "            if stim_to_stim:\n",
    "                end_idx = find_nearest(times, trials['stimOn_times'][tr + 1])\n",
    "            else:\n",
    "                if sr[be] == 'T_BIN':\n",
    "                    end_idx = start_idx + int(duration / T_BIN)\n",
    "                else:\n",
    "                    fs = sr[be]\n",
    "                    end_idx = start_idx + int(duration * fs)\n",
    "\n",
    "            if (pawex and ('paw' in be)):  # for illustration on frame\n",
    "                D[be].append([series[start_idx:end_idx, 0],\n",
    "                              series[start_idx:end_idx, 1]])\n",
    "            else:\n",
    "                if start_idx > len(series):\n",
    "                    print('start_idx > len(series)')\n",
    "                    break\n",
    "                D[be].append(series[start_idx:end_idx])\n",
    "\n",
    "        D['T'].append(tr)\n",
    "        kk += 1\n",
    "\n",
    "    print(kk, 'trials used')\n",
    "    return D\n",
    "\n",
    "\n",
    "'''\n",
    "####\n",
    "batch processing\n",
    "####\n",
    "'''\n",
    "\n",
    "\n",
    "def get_PSTHs_7behaviors(lag=-0.4):\n",
    "    '''\n",
    "    run once with lag = -0.6, -0.4\n",
    "    '''\n",
    "\n",
    "    df = bwm_query(one)\n",
    "    eids = list(set(df['eid'].values))\n",
    "\n",
    "    R = {}\n",
    "    plt.ioff()\n",
    "    for eid in eids:\n",
    "\n",
    "        try:\n",
    "            # only let sessions pass that have dlc passed for both side cams\n",
    "            qc = pd.read_csv(os.path.join(Path(__file__).parents[2], 'data_checks', 'qc_video_data.csv'))\n",
    "            qc = qc.loc[qc['eid'] == eid]\n",
    "            qc_left = qc.loc[qc['label'] == 'left']\n",
    "            qc_right = qc.loc[qc['label'] == 'right']\n",
    "            if not (qc_left.iloc[0]['dlc'] and qc_right.iloc[0]['dlc']):\n",
    "                continue\n",
    "\n",
    "            R[eid] = PSTH_pseudo(eid, lag=lag, duration=0.4)\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "            print(f'something off with {eid}')\n",
    "            continue\n",
    "\n",
    "    s = (pth_res / f'behave7_{abs(lag)}.npy')\n",
    "    np.save(s, R, allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "##########\n",
    "plotting \n",
    "##########\n",
    "'''\n",
    "\n",
    "def Result_7behave(hists=False, save_df=False, bf = True):\n",
    "    '''\n",
    "    bar plot\n",
    "    Used in overleaf motor-correlates figure\n",
    "    '''\n",
    "\n",
    "    behave7 = ['licking', 'whisking_l', 'whisking_r',\n",
    "               'wheeling', 'nose_pos', 'paw_pos_r', 'paw_pos_l']\n",
    "\n",
    "    infos = {'0.4': [[], '-0.4 s to stim'],\n",
    "             '0.6': [[], '-0.6 to -0.2 s to stim']}\n",
    "\n",
    "    if hists:\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(3, 4))\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "    bwidth = 0.25\n",
    "\n",
    "    cs = ['purple', 'orange']\n",
    "    k = 0\n",
    "    for t in ['0.4', '0.6']:\n",
    "        s = (pth_res / f'behave7_{t}.npy')\n",
    "\n",
    "        R = np.load(s, allow_pickle=True).flat[0]\n",
    "\n",
    "        ms = ['dist', 'p', 'dom']\n",
    "\n",
    "        c1 = [[x + '_' + y for y in ms] for x in behave7]\n",
    "        c1flat = [item for sublist in c1 for item in sublist]\n",
    "        c1flat.insert(0, 'eid')\n",
    "        columns = c1flat\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for eid in R:\n",
    "            flag = False\n",
    "            l = []\n",
    "            if R[eid] == (None, None):\n",
    "                continue\n",
    "            else:\n",
    "                for b in R[eid]:\n",
    "                    if flag:\n",
    "                        break\n",
    "                    for j in R[eid][b]:\n",
    "\n",
    "                        if not isinstance(j, str) and np.isnan(j):\n",
    "                            flag = True\n",
    "                            break\n",
    "                        l.append(j)\n",
    "\n",
    "                if flag:\n",
    "                    continue\n",
    "                else:\n",
    "                    l.insert(0, eid)\n",
    "                    r.append(l)\n",
    "\n",
    "        df = pd.DataFrame(data=r, columns=columns)\n",
    "\n",
    "        vals = [sum(df[x + '_p'] < 0.05) / len(df) for x in behave7]\n",
    "\n",
    "        # check how many sessions have at least one modulated behavior\n",
    "        ps = [x + '_p' for x in behave7]\n",
    "        rr = [[float(df[df['eid'] == eid][y]) for y in ps]\n",
    "              for eid in df['eid']]\n",
    "        sigs = np.zeros(len(rr))\n",
    "        sigs0 = np.zeros(len(rr))\n",
    "        for i in range(len(rr)):\n",
    "            if any(np.array(rr[i]) * len(behave7) < 0.05):\n",
    "                sigs[i] = 1  # Bonferroni corrected\n",
    "            if any(np.array(rr[i]) < 0.05):\n",
    "                sigs0[i] = 1  # uncorrected\n",
    "\n",
    "        df['atLeastOne_p<0.05'] = sigs0\n",
    "        df['atLeastOne_p<0.05_BF'] = sigs\n",
    "\n",
    "        sigs = sum(sigs) if bf else sum(sigs0)\n",
    "\n",
    "        print(t, (f'{sigs} out of {len(rr)}'\n",
    "              ' have at least one behavior modulated'))\n",
    "\n",
    "        vals.append(float(sigs) / len(rr))\n",
    "        infos[t][0].append(vals)\n",
    "\n",
    "        ax.barh(np.arange(len(vals)) + k * 0.25, list(reversed(vals)),\n",
    "                height=bwidth, label=infos[t][1], color=cs[k])\n",
    "\n",
    "        if save_df:\n",
    "            df.to_pickle(pth_res / 'ME.pkl')\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    ax.axvline(x=0.05, linestyle='--', c='k')\n",
    "    ax.set_yticks(range(len(behave7) + 1))\n",
    "    ax.set_yticklabels(list(reversed(behave7 + ['at least one'])))\n",
    "    ax.set_xlabel('fraction of sessions with p<0.05')\n",
    "    print(f'{len(df)} sessions, {len(behave7)} behaviors \\n'\n",
    "          f'tested for block modulation \\n')\n",
    "    ax.set_ylabel('behavior')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(ncol=1, frameon=False).set_draggable(True)\n",
    "\n",
    "    if hists:\n",
    "        ax = plt.subplot(1, 2, 2, sharey=ax)\n",
    "        r2 = []\n",
    "        cols2 = ['behavior', 'p']\n",
    "        for eid in R:\n",
    "            for b in R[eid]:\n",
    "                r2.append([b, R[eid][b][1]])\n",
    "\n",
    "        df = pd.DataFrame(data=r2, columns=cols2)\n",
    "\n",
    "        sns.violinplot(y=\"behavior\", x=\"p\",\n",
    "                       data=df, inner=None,\n",
    "                       color=\".8\", split=True, meanline=True, bw=.01,\n",
    "                       orient='h')\n",
    "\n",
    "        plt.axvline(x=0.05, linestyle='--', c='gray',\n",
    "                    label='p=0.05')\n",
    "\n",
    "        plt.title('smoothed historgam of p-values')\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "def PSTH_pseudo(eid, duration=0.4, lag=-0.4, plotting=True,\n",
    "                control=False, query_type='remote', pawex=False):\n",
    "    '''\n",
    "    function to plot PSTH of whisking or licking in\n",
    "    inter-trial interval, split by block,\n",
    "    with pseudo-session control\n",
    "\n",
    "    TO PLOT OVERLEAF MOTOR CORRELATE EXAMPLE,  \n",
    "    paw example --> pawex = True\n",
    "    eid = \"15f742e1-1043-45c9-9504-f1e8a53c1744\"\n",
    "    param: control, boolean. If True, subdivide PSTH by choice\n",
    "    '''\n",
    "\n",
    "    if pawex:\n",
    "        sr0 = {'paw_pos_l': 60}\n",
    "    else:\n",
    "        sr0 = sr\n",
    "\n",
    "    D = cut_behavior(eid, lag=lag, duration=duration,\n",
    "                     query_type=query_type)\n",
    "\n",
    "    if len(Counter(D['pleft'])) != 3:\n",
    "        print('no block structure')\n",
    "        return None, None\n",
    "\n",
    "    if plotting:\n",
    "        plt.figure(figsize=(len(sr0) * 18 / 7, 6))\n",
    "        Ax = [plt.subplot(2, len(sr0), q) for q in range(1, 2 * len(sr0) + 1)]\n",
    "\n",
    "    Res = {}\n",
    "\n",
    "    k = 0\n",
    "    for motor in sr0:\n",
    "        if sr0[motor] == 'T_BIN':\n",
    "            xs = np.arange(duration / T_BIN) * T_BIN\n",
    "        else:\n",
    "            fs = sr0[motor]\n",
    "            xs = np.arange(duration * fs) / fs\n",
    "\n",
    "        xs = xs + lag\n",
    "\n",
    "        D2 = {}\n",
    "\n",
    "        null_d = []\n",
    "        n_pseudo = 1000\n",
    "\n",
    "        for i in range(n_pseudo):\n",
    "            pb = generate_pseudo_blocks(len(D['pleft']))\n",
    "\n",
    "            left_block = np.nanmean(\n",
    "                (np.array(\n",
    "                    D[motor])[\n",
    "                    np.where(\n",
    "                        np.array(pb) == 0.8)[0]]),\n",
    "                axis=0)\n",
    "            right_block = np.nanmean(\n",
    "                (np.array(D[motor])[np.where(np.array(pb) == 0.2)[0]]), axis=0)\n",
    "\n",
    "            D2[f'p_{i}_{i + 1}'] = abs(left_block - right_block)\n",
    "            null_d.append(np.nanmean(D2[f'p_{i}_{i + 1}']))\n",
    "\n",
    "            if plotting:\n",
    "\n",
    "                if i == 0:\n",
    "                    l1 = f'{n_pseudo} x pseudo'\n",
    "                else:\n",
    "                    l1 = '_nolegend_'\n",
    "\n",
    "                Ax[k].plot(xs, left_block, label=l1, c='gray', linewidth=0.5)\n",
    "                Ax[k].plot(xs, right_block, c='gray', linewidth=0.5)\n",
    "\n",
    "        left_block = np.nanmean(\n",
    "            (np.array(\n",
    "                D[motor])[\n",
    "                np.where(\n",
    "                    np.array(\n",
    "                        D['pleft']) == 0.8)[0]]),\n",
    "            axis=0)\n",
    "        right_block = np.nanmean(\n",
    "            (np.array(\n",
    "                D[motor])[\n",
    "                np.where(\n",
    "                    np.array(\n",
    "                        D['pleft']) == 0.2)[0]]),\n",
    "            axis=0)\n",
    "\n",
    "        D2['left_right'] = abs(left_block - right_block)\n",
    "\n",
    "        if control:\n",
    "\n",
    "            ts = []\n",
    "            for pl in [0.8, 0.2]:\n",
    "                for ch in [1, -1]:\n",
    "\n",
    "                    b1 = np.where(np.array(D['pleft']) == pl)[0]\n",
    "                    b2 = np.where(np.array(D['choices']) == ch)[0]\n",
    "                    s = np.array(list(set(b1).intersection(set(b2))))\n",
    "                    ts.append(np.nanmean((np.array(D[motor])[s]), axis=0))\n",
    "\n",
    "        # for each observation, get p value between distance\n",
    "        # of real block psth curves and distances for the pseudo\n",
    "        # session PSTH curves\n",
    "\n",
    "        # save on which block is more whisking\n",
    "        if (np.nanmean(left_block) - np.nanmean(right_block)) < 0:\n",
    "            dom = 'pleft02'\n",
    "        else:\n",
    "            dom = 'pleft08'\n",
    "\n",
    "        # average distances across observations\n",
    "        samp = np.nanmean(D2['left_right'])\n",
    "\n",
    "        # p value via percentile\n",
    "        alpha = np.mean(np.array(null_d + [samp]) >= samp)\n",
    "\n",
    "        # z-scored distance\n",
    "        samp = (samp - np.mean(null_d)) / np.std(null_d)\n",
    "\n",
    "        Res[motor] = [samp, alpha, dom]\n",
    "\n",
    "        if plotting:\n",
    "\n",
    "            Ax[k].plot(xs, left_block, label='p(l) = 0.8', c=blue_left)\n",
    "            Ax[k].plot(xs, right_block, label='p(l) = 0.2', c=red_right)\n",
    "\n",
    "            if control:\n",
    "\n",
    "                cols = ['burlywood', 'coral', 'lime', 'teal']\n",
    "                labs = ['pleft0.8_choice1', 'pleft0.8_choice-1',\n",
    "                        'pleft0.2_choice1', 'pleft0.2_choice-1']\n",
    "\n",
    "                for i in range(len(ts)):\n",
    "                    Ax[k].plot(xs, ts[i], label=labs[i], c=cols[i])\n",
    "\n",
    "            Ax[k].axvline(x=0, linestyle='--',\n",
    "                          label='stimOn', color='pink')\n",
    "            Ax[k].set_xlabel('time [sec]')\n",
    "            Ax[k].set_ylabel(motor)\n",
    "            Ax[k].set_title(f'{motor} \\n'\n",
    "                            f'dist={np.round(samp,3)} \\n'\n",
    "                            f'p={np.round(alpha,2)}', fontsize=15)\n",
    "\n",
    "            if k == 0:\n",
    "                Ax[k].legend().set_draggable(True)\n",
    "#            ax1.axvspan(abs(lag)-0.6, abs(lag)-0.2, facecolor='pink',\n",
    "#                        alpha=0.3)\n",
    "\n",
    "            # Plot motor per trial\n",
    "\n",
    "            cols = [cdi[x] for x in D['pleft']]\n",
    "            ttype = list(Counter(D['pleft']).keys())\n",
    "\n",
    "            Ax[k + len(sr0)].scatter(D['T'],\n",
    "                                     np.nanmean(D[motor], axis=1),\n",
    "                                     c=cols, s=1)\n",
    "\n",
    "            Ax[k + len(sr0)].set_ylabel(f'{motor}')\n",
    "            Ax[k + len(sr0)].set_xlabel('trial number')\n",
    "            legend_elements = [\n",
    "                Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker='o',\n",
    "                    color=cdi[y],\n",
    "                    label=y,\n",
    "                    markerfacecolor=cdi[y],\n",
    "                    markersize=5,\n",
    "                    linestyle='') for y in ttype]\n",
    "            if k == 0:\n",
    "                Ax[k + len(sr0)].legend(handles=legend_elements,\n",
    "                                        loc='best').set_draggable(True)\n",
    "\n",
    "        k += 1\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if plotting:\n",
    "        pa = one.eid2path(eid)\n",
    "        n = '_'.join([str(pa).split('/')[i] for i in [4, 6, 7, 8]])\n",
    "        plt.suptitle(f'{n}')\n",
    "        plt.tight_layout()\n",
    "#        plt.savefig('/home/mic/paper-brain-wide-map/'\n",
    "#                    f'behavioral_block_correlates/figs/'\n",
    "#                    f'7_behaviors0.4/{n}__{eid}.png')\n",
    "        # plt.close()\n",
    "\n",
    "    del D\n",
    "    return Res\n",
    "\n",
    "def paw_position_onframe(eid, ax=None, fig=None):\n",
    "    '''\n",
    "    load example video frame\n",
    "    scatter plot average inter-trial-interval\n",
    "    left paw position locations on top\n",
    "    '''\n",
    "\n",
    "    behave = 'paw_pos_l'\n",
    "\n",
    "    img_file = os.path.join(os.getcwd(), f'{eid}_left.npy')\n",
    "    r = np.load(img_file)[0]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ax.imshow(r, cmap='gray', origin=\"upper\")\n",
    "\n",
    "    D = cut_behavior(eid, pawex=True)\n",
    "\n",
    "    # get list of colors according to\n",
    "\n",
    "    cols = [cdi[x] for x in D['pleft']]\n",
    "\n",
    "    xs = [np.mean(u[0]) for u in D[behave]]\n",
    "    ys = [np.mean(u[1]) for u in D[behave]]\n",
    "\n",
    "    # plot in random order for better visibility\n",
    "    # plot only every nth trial\n",
    "    n = 1\n",
    "    ids = np.arange(len(xs))\n",
    "    random.shuffle(ids)\n",
    "    xs = np.array(xs)[ids][::n]\n",
    "    ys = np.array(ys)[ids][::n]\n",
    "    cols = np.array(cols, dtype=object)[ids][::n]\n",
    "    print(xs[:3], ys[:3])\n",
    "    ax.scatter(xs, ys, c=cols, s=200, alpha=1, marker='x')\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker='x',\n",
    "            color=cdi[y],\n",
    "            label=f'p(l)={y}',\n",
    "            markerfacecolor=cdi[y],\n",
    "            markersize=8,\n",
    "            linestyle='') for y in Counter(\n",
    "            D['pleft']).keys()]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='lower right',\n",
    "               prop={'size': 8}).set_draggable(True)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    return D\n",
    "    # continue here\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eid = '15f742e1-1043-45c9-9504-f1e8a53c1744'\n",
    "\n",
    "    #  cut seven behaviors for all BWM sessions\n",
    "    for lag in [-0.4, -0.6]:\n",
    "        if not os.path.exists((pth_res / f'behave7_{abs(lag)}.npy')):\n",
    "            get_PSTHs_7behaviors(lag = lag)\n",
    "\n",
    "    # activate interactive plotting to see figures\n",
    "    plt.ion()\n",
    "\n",
    "    #  plot bar plot summarising fraction of sessions that \n",
    "    #  have sig motor correlates\n",
    "    Result_7behave()\n",
    "    \n",
    "    paw_position_onframe(eid)\n",
    "    \n",
    "    # illustrate paw behavior per trial \n",
    "    PSTH_pseudo(eid,pawex=True)\n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibl_bwm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1b401dfd2fadf2dbb7769f733a3b6a0305e9b9e3f345677805a62907b1fd5b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
