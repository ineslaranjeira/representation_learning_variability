{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-movement characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/iblenv/lib/python3.10/site-packages/one/api.py:1577: UserWarning: Newer cache tables require ONE version 2.7 or greater\n",
      "  warnings.warn(f'Newer cache tables require ONE version {min_version} or greater')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "IMPORTS\n",
    "\"\"\"\n",
    "import os\n",
    "import autograd.numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# --Machine learning and statistics+\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "import umap\n",
    "\n",
    "from one.api import ONE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "\n",
    "# Get my functions\n",
    "functions_path =  '/home/ines/repositories/representation_learning_variability/Functions/'\n",
    "functions_path = '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/Functions/'\n",
    "os.chdir(functions_path)\n",
    "# from plotting_functions import bins_per_trial_phase, broader_label\n",
    "from data_processing import process_quiescence\n",
    "from wheel_functions import wheel_trial_epoch\n",
    "one = ONE(base_url='https://alyx.internationalbrainlab.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =  '/home/ines/repositories/representation_learning_variability/DATA/Sub-trial/Design matrix/'\n",
    "data_path =  '/Users/ineslaranjeira/Documents/Repositories/representation_learning_variability/DATA/Sub-trial/Design matrix/'\n",
    "os.chdir(data_path)\n",
    "session_all = pickle.load(open('last_3_training_2024-04-23', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/d2j3zp9d1xzb8wgfrw81j0c40000gn/T/ipykernel_86453/2079758226.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  session_trials['index'] = np.arange(0, len(session_trials))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['time'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m  df \u001b[38;5;241m=\u001b[39m wheel_trial_epoch(one, session_trials, session, bin_size, threshold, min_period)\u001b[38;5;241m.\u001b[39mdropna()  \n\u001b[1;32m     27\u001b[0m  df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwheel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigned_contrast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreaction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoice\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobabilityLeft\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m---> 31\u001b[0m  processed_quiescence \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_quiescence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m  \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[1;32m     34\u001b[0m  processes_quiescence_all[mouse_name][session] \u001b[38;5;241m=\u001b[39m processed_quiescence\n",
      "File \u001b[0;32m~/Documents/Repositories/representation_learning_variability/Functions/data_processing.py:156\u001b[0m, in \u001b[0;36mprocess_quiescence\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Filter DataFrame to remove consecutive duplicates\u001b[39;00m\n\u001b[1;32m    154\u001b[0m df_no_consecutive_duplicates \u001b[38;5;241m=\u001b[39m new[\u001b[38;5;241m~\u001b[39mconsecutive_duplicates_mask\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m--> 156\u001b[0m time_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    157\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m df_no_consecutive_duplicates\u001b[38;5;241m.\u001b[39mmerge(time_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovement_onset\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m/opt/anaconda3/envs/iblenv/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/iblenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/iblenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['time'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "threshold = 0.2 # Need to check if this makes sense\n",
    "min_period = 400 # This is to match the minimum length of quiescence periods\n",
    "bin_size = 0.05\n",
    "\n",
    "# Save data of all sessions for latter\n",
    "processes_quiescence_all = defaultdict(list)\n",
    "perf_idx = pd.DataFrame(columns=['performance_easy', 'idx'])\n",
    "\n",
    "# Loop through animals\n",
    "mouse_names = list(session_all.keys())\n",
    "for m, mouse_name in enumerate(mouse_names):\n",
    "    processes_quiescence_all[mouse_name] = {}\n",
    "\n",
    "    # Find data of interest\n",
    "    mouse_data = session_all[mouse_name]\n",
    "    mouse_session_num = np.max(mouse_data['training_day'])\n",
    "    use_data = mouse_data.loc[mouse_data['training_day'] >= mouse_session_num - 2]\n",
    "\n",
    "    # Loop through sessions\n",
    "    mouse_sessions = use_data['session'].unique()\n",
    "    for s, session in enumerate(mouse_sessions):\n",
    "        \n",
    "        session_trials = use_data.loc[use_data['session']==session]\n",
    "        session_trials['index'] = np.arange(0, len(session_trials))\n",
    "        \n",
    "        df = wheel_trial_epoch(one, session_trials, session, bin_size, threshold, min_period).dropna()  \n",
    "        df = df[['trial', 'wheel', 'movement', 'trial_epoch', 'feedback',\n",
    "       'next_feedback', 'signed_contrast', 'response', 'reaction', 'choice',\n",
    "       'probabilityLeft']].drop_duplicates()\n",
    "    \n",
    "        processed_quiescence = process_quiescence(df)\n",
    "\n",
    "        # Save\n",
    "        processes_quiescence_all[mouse_name][session] = processed_quiescence\n",
    "        \n",
    "        # Save performance also\n",
    "        perf_mouse = pd.DataFrame(columns=['performance_easy', 'idx'], index=range(1))\n",
    "        perf_mouse['idx'] = session\n",
    "        perf_mouse['performance_easy'] = np.nanmean(session_trials['correct_easy'])\n",
    "        \n",
    "        # Save performance results\n",
    "        if s == 0:\n",
    "            perf_idx = perf_mouse\n",
    "        else:\n",
    "            perf_idx = perf_idx.append(perf_mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21541729b5da47a594818561e91cb4175a7e192d68b7cc4221509f43b2f902b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
