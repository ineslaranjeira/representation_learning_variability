{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for plotting pose estimates on top of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neurodsp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# conda install -c conda-forge pyarrow\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmooth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m smooth_interpolate_savgol\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrainbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SessionLoader\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neurodsp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from one.api import ONE\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os,fnmatch\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "# conda install -c conda-forge pyarrow\n",
    "import os\n",
    "from neurodsp.smooth import smooth_interpolate_savgol\n",
    "from brainbox.io.one import SessionLoader\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/miniconda3/envs/iblenv/lib/python3.9/site-packages/one/webclient.py:127: RuntimeWarning: Failed to connect, returning cached response\n",
      "  warnings.warn('Failed to connect, returning cached response', RuntimeWarning)\n",
      "/home/ines/miniconda3/envs/iblenv/lib/python3.9/site-packages/one/api.py:1465: UserWarning: Newer cache tables require ONE version 2.7 or greater\n",
      "  warnings.warn(f'Newer cache tables require ONE version {min_version} or greater')\n"
     ]
    }
   ],
   "source": [
    "#one = ONE(base_url='https://openalyx.internationalbrainlab.org',\n",
    "#      password='international', silent=True)\n",
    "\n",
    "one = ONE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find(pattern, path):\n",
    "\n",
    "    '''\n",
    "    find a local video like so:\n",
    "    flatiron='/home/mic/Downloads/FlatIron'      \n",
    "    vids = Find('*.mp4', flatiron)\n",
    "    '''\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, pattern):\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def load_lp(eid, cam, masked=True, paws=True,\n",
    "            reso='128x102_128x128', flav='multi'):\n",
    "\n",
    "    '''\n",
    "    for a given session and cam, load all lp tracked points;\n",
    "    that's paw specific now; \n",
    "    flav is either single or multi view EKS\n",
    "    '''\n",
    "    \n",
    "    print(f'loading LP, {reso}, {cam}')\n",
    "    print(f'{flav}, paws:{paws}, {eid}')\n",
    "    \n",
    "    if paws:\n",
    "    \n",
    "        # pth = ('/mnt/8cfe1683-d974-40f3-a20b-b217cad4722a/lp_ens'\n",
    "        #       f'/{reso}/{eid}/ensembles_{cam}Camera/'\n",
    "        #       f'_iblrig_{cam}Camera.raw.paws.eks_{flav}.csv') \n",
    "        pth = ('/mnt/616e7cfa-ba4d-4fbf-9400-dc0640f8238f/lp_ens'\n",
    "              f'/{reso}/{eid}/ensembles_{cam}Camera/'\n",
    "              f'_iblrig_{cam}Camera.raw.paws.eks_{flav}.csv') \n",
    "\n",
    "\n",
    "        d0 = pd.read_csv(pth, low_memory=False)\n",
    "\n",
    "\n",
    "        if reso[:7] == '128x102':\n",
    "            scale = 10 if cam == 'left' else 5\n",
    "        else:    \n",
    "            scale = 4 if cam == 'left' else 2\n",
    "\n",
    "        print('scale', scale)\n",
    "       \n",
    "        # concat column keys\n",
    "        d = {}\n",
    "        for k in d0:\n",
    "            if (d0[k][1] in ['x','y']):\n",
    "                d[d0[k][0]+'_'+d0[k][1]] = scale * np.array(\n",
    "                                               d0[k][2:].values, \n",
    "                                               dtype=np.float32)\n",
    "            else:\n",
    "                d[d0[k][0]+'_'+d0[k][1]] = np.array(\n",
    "                                               d0[k][2:].values, \n",
    "                                               dtype=np.float32)                \n",
    "          \n",
    "             \n",
    "        del d['bodyparts_coords']\n",
    "        \n",
    "#        k0 = list(d.keys())\n",
    "#        for k in k0:\n",
    "#            if 'likelihood' in k:\n",
    "#                del d[k]    \n",
    "\n",
    "    d = {}  # Ines added\n",
    "    d['times'] = np.load(one.eid2path(eid) / 'alf'\n",
    "                    / f'_ibl_leftCamera.times.npy')\n",
    "                    \n",
    "\n",
    "    ls = [len(d[x]) for x in d]\n",
    "    if not all(ls == np.mean(ls)):\n",
    "        lsd = {x:len(d[x]) for x in d}\n",
    "        print(f'length mismatch: {lsd}')\n",
    "        print(eid, cam)\n",
    "        print('cutting times')\n",
    "        d['times'] = d['times'][:ls[0]]\n",
    "\n",
    "    # Ines: I think only this part of the code is taking effect; what is done previously is overwritten...\n",
    "    if (not paws and reso == '128x102_128x128'):\n",
    "        # load old complete lp file        \n",
    "        # pth = ('/mnt/616e7cfa-ba4d-4fbf-9400-dc0640f8238f/lp_ens'\n",
    "        #       f'/{reso}/{eid}/_ibl_{cam}Camera.lightningPose.pqt') \n",
    "        # pth = ('/home/ines/Downloads/_ibl_leftCamera.lightningPose.30a17aa2-1c01-4b29-a28c-2ab4f13bce7e.pqt') \n",
    "        pth = ('/home/ines/Downloads/_ibl_leftCamera.lightningPose.6129d18a-61ca-48f7-990a-c93552674db6.pqt') \n",
    "        # pth = ('/home/ines/Downloads/_ibl_leftCamera.lightningPose.b6f15e64-4311-4500-ac52-aebcfa8eb528.pqt')\n",
    "        d = pd.read_parquet(pth)    \n",
    "\n",
    "        if masked:\n",
    "            points = np.unique(['_'.join(x.split('_')[:-1]) \n",
    "                                for x in d.keys()])[1:]\n",
    "        \n",
    "            for point in points:\n",
    "                cond = d[f'{point}_likelihood'] < 0.9\n",
    "                d.loc[cond, [f'{point}_x', f'{point}_y']] = np.nan\n",
    "\n",
    "    return d\n",
    "\n",
    "# eids of interest\n",
    "\"7330f879-8dfc-4344-af84-cd422199bddc\"  # KS014 21/08/2019\n",
    "\"c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee\"  # KS014 20/08/2019\n",
    "\"616e7cfa-ba4d-4fbf-9400-dc0640f8238f\"  # KS014 19/08/2019\n",
    "    if manual:\n",
    "        pth = one.eid2path(eid)    \n",
    "        d = pd.read_parquet(pth / 'alf' / f'_ibl_{cam}Camera.dlc.pqt')\n",
    "        d['times'] = np.load(one.eid2path(eid) / 'alf'\n",
    "                    / f'_ibl_{cam}Camera.times.npy')\n",
    "                    \n",
    "        ls = [len(d[x]) for x in d]\n",
    "        if not all(ls == np.mean(ls)):\n",
    "            lsd = {x:len(d[x]) for x in d}\n",
    "            print(f'length mismatch: {lsd}')\n",
    "            print(eid, cam)\n",
    "            print('cutting times')\n",
    "            d['times'] = d['times'][:ls[0]]            \n",
    "\n",
    "    else:\n",
    "        # load DLC\n",
    "        sess_loader = SessionLoader(one, eid)\n",
    "        sess_loader.load_pose(views=[cam])\n",
    "        d = sess_loader.pose[f'{cam}Camera']\n",
    "    \n",
    "    if smoothed:\n",
    "        print('smoothing dlc traces')\n",
    "        window = 13 if cam == 'right' else 7\n",
    "        sers = [x for x in d.keys() if (x[-1] in ['x','y'])]# and 'paw' in x\n",
    "        for ser in sers:\n",
    "            d[ser] = smooth_interpolate_savgol(\n",
    "                d[ser].to_numpy(),\n",
    "                window=window,order=3, interp_kind='linear')   \n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Viewer(eid, video_type, frame_start, frame_stop, save_video=True, \n",
    "           eye_zoom=False, lp=False, ens=False,\n",
    "           res = '128x102_128x128', masked=True, paws_only=False,\n",
    "           smooth_dlc = False):\n",
    "           \n",
    "    '''\n",
    "    eid: session id, e.g. '3663d82b-f197-4e8b-b299-7b803a155b84'\n",
    "    video_type: one of 'left', 'right', 'body'\n",
    "    save_video: video is saved this local folder\n",
    "\n",
    "    Example usage to view and save labeled video with wheel angle:\n",
    "    Viewer('3663d82b-f197-4e8b-b299-7b803a155b84', 'left', [5,7])\n",
    "    3D example: 'cb2ad999-a6cb-42ff-bf71-1774c57e5308', [5,7]\n",
    "    \n",
    "    Different resolutions:\n",
    "    128x102_128x128\n",
    "    320x256_128x128\n",
    "    320x256_256x256\n",
    "    \n",
    "    \n",
    "    paws: paws only\n",
    "    '''\n",
    "\n",
    "    save_vids_here = Path.home()\n",
    "\n",
    "\n",
    "    alf_path = one.eid2path(eid)\n",
    "\n",
    "    # Download a single video\n",
    "    video_path = (alf_path / \n",
    "        f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4')\n",
    "    \n",
    "    if not os.path.isfile(video_path):\n",
    "        print('mp4 not found locally, downloading it ...')\n",
    "        video_path = one.load_dataset(eid,\n",
    "            f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4',\n",
    "            download_only=True)\n",
    "\n",
    "\n",
    "    # Download DLC traces and stamps\n",
    "    Times = one.load_dataset(eid,f'alf/_ibl_{video_type}Camera.times.npy')\n",
    "    \n",
    "    \n",
    "    if lp and ens:\n",
    "        print('either lp or ens must be False')\n",
    "        return\n",
    "     \n",
    "    if lp:\n",
    "\n",
    "        cam = load_lp(eid, video_type, paws=False,\n",
    "              reso=res, flav='multi')\n",
    "              \n",
    "              \n",
    "        print(cam.keys())        \n",
    "   \n",
    "    elif ens:\n",
    "        print('load ensembling results')\n",
    "        pth = Path('/mnt/8cfe1683-d974-40f3-a20b-b217cad4722a/lp_ens'\n",
    "          f'/{res}/{eid}/ensembles_{video_type}Camera')\n",
    "\n",
    "        cams = []\n",
    "        nets = 4 if res[:7] == '320x256' else 5\n",
    "        \n",
    "        if res[:7] == '128x102':\n",
    "            scale = 10 if video_type == 'left' else 5\n",
    "        else:    \n",
    "            scale = 4 if video_type == 'left' else 2\n",
    "\n",
    "        for net in range(nets):   \n",
    "            cam = {}\n",
    "#            try:\n",
    "#                df = pd.read_csv(pth / \n",
    "#                        f'_iblrig_{video_type}Camera.raw.eye{net}.csv')\n",
    "#                cam = cam | {'_'.join([df[x][0],df[x][1]]): \n",
    "#                         scale* np.array(list(map(float, df[x][2:]))) \n",
    "#                         for x in df.keys() if df[x][1] in ['x','y','likelihood']}\n",
    "#            except:\n",
    "#                pass\n",
    "                \n",
    "            df = pd.read_csv(pth / f'_iblrig_{video_type}Camera.raw.paws{net}.csv')\n",
    "\n",
    "            cam = cam | {'_'.join([df[x][0],df[x][1]]): \n",
    "                     scale* np.array(list(map(float, df[x][2:]))) \n",
    "                     for x in df.keys() if df[x][1] in ['x','y','likelihood']}\n",
    "                     \n",
    "            cams.append(cam)\n",
    "                    \n",
    "        cam = cams[0]           \n",
    "        \n",
    "    else: \n",
    "        print('loading dlc')\n",
    "        cam = load_dlc(eid, video_type, smoothed=smooth_dlc)\n",
    "                                                      \n",
    "    # get video info\n",
    "    cap = cv2.VideoCapture(video_path.as_uri())\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    size = (int(cap.get(3)), int(cap.get(4)))\n",
    "\n",
    "\n",
    "    print(eid,\n",
    "          ', ',\n",
    "          video_type,\n",
    "          ', fsp:',\n",
    "          fps,\n",
    "          ', #frames:',\n",
    "          length,\n",
    "          ', #stamps:',\n",
    "          len(Times),\n",
    "          ', #frames - #stamps = ',\n",
    "          length - len(Times))\n",
    "\n",
    "    # pick trial range for which to display stuff\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "\n",
    "    print('frame start stop', frame_start, frame_stop)\n",
    "\n",
    "    '''\n",
    "    load wheel\n",
    "    '''\n",
    "\n",
    "    wheel = one.load_object(eid, 'wheel')\n",
    "    import brainbox.behavior.wheel as wh\n",
    "    try:\n",
    "        pos, t = wh.interpolate_position(\n",
    "            wheel['timestamps'], wheel['position'], freq=1000)\n",
    "    except BaseException:\n",
    "        pos, t = wh.interpolate_position(\n",
    "            wheel['times'], wheel['position'], freq=1000)\n",
    "\n",
    "    w_start = find_nearest(t, Times[frame_start])\n",
    "    w_stop = find_nearest(t, Times[frame_stop])\n",
    "\n",
    "    # confine to interval\n",
    "    pos_int = pos[w_start:w_stop]\n",
    "    t_int = t[w_start:w_stop]\n",
    "\n",
    "    # alignment of cam stamps and interpolated wheel stamps\n",
    "    wheel_pos = []\n",
    "    kk = 0\n",
    "    for wt in Times[frame_start:frame_stop]:\n",
    "        wheel_pos.append(pos_int[find_nearest(t_int, wt)])\n",
    "        kk += 1\n",
    "        if kk % 3000 == 0:\n",
    "            print('iteration', kk)\n",
    "\n",
    "    '''\n",
    "    DLC related stuff\n",
    "    '''\n",
    "    Times = Times[frame_start:frame_stop]\n",
    "    Frames = np.arange(frame_start, frame_stop)\n",
    "    \n",
    "    \n",
    "    # liklihood threshold\n",
    "    l_thr = 0.9 if masked else -1\n",
    "\n",
    "    points = [x[:-2] for x in cam.keys() if x[-1] == 'x']\n",
    "\n",
    "    if video_type != 'body':\n",
    "        try:\n",
    "            d = list(points)\n",
    "            d.remove('tube_top')\n",
    "            d.remove('tube_bottom')\n",
    "            points = d\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if paws_only:\n",
    "        p2 = deepcopy(points)\n",
    "        for point in p2:\n",
    "            if not 'paw' in point:\n",
    "                points.remove(point)            \n",
    "\n",
    "    points = np.array(points)\n",
    "    \n",
    "    if ens:\n",
    "\n",
    "        XYss = []\n",
    "        \n",
    "        for cam in cams:\n",
    "            # Set values to nan if likelyhood is too low # for pqt: .to_numpy()\n",
    "            XYs = {}\n",
    "            for point in points:\n",
    "                x = np.ma.masked_where(\n",
    "                    cam[point + '_likelihood'] < l_thr, cam[point + '_x'])\n",
    "                x = x.filled(np.nan)\n",
    "                y = np.ma.masked_where(\n",
    "                    cam[point + '_likelihood'] < l_thr, cam[point + '_y'])\n",
    "                y = y.filled(np.nan)\n",
    "                XYs[point] = np.array(\n",
    "                    [x[frame_start:frame_stop], y[frame_start:frame_stop]])        \n",
    "        \n",
    "            XYss.append(XYs)    \n",
    "        cam = cams[0]\n",
    "        \n",
    "        \n",
    "    # Set values to nan if likelyhood is too low # for pqt: .to_numpy()\n",
    "    XYs = {}\n",
    "    for point in points:\n",
    "        x = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < l_thr, cam[point + '_x'])\n",
    "        x = x.filled(np.nan)\n",
    "        y = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < l_thr, cam[point + '_y'])\n",
    "        y = y.filled(np.nan)\n",
    "        XYs[point] = np.array(\n",
    "            [x[frame_start:frame_stop], y[frame_start:frame_stop]])        \n",
    "        \n",
    "\n",
    "    # Just for 3D testing\n",
    "    # return XYs\n",
    "\n",
    "    # Zoom at eye\n",
    "    if eye_zoom:\n",
    "        pivot = np.nanmean(XYs['pupil_top_r'], axis=1)\n",
    "        x0 = int(pivot[0]) - 33\n",
    "        x1 = int(pivot[0]) + 33\n",
    "        y0 = int(pivot[1]) - 28\n",
    "        y1 = int(pivot[1]) + 38\n",
    "        size = (66, 66)\n",
    "        dot_s = 1  # [px] for painting DLC dots\n",
    "\n",
    "    else:\n",
    "        x0 = 0\n",
    "        x1 = size[0]\n",
    "        y0 = 0\n",
    "        y1 = size[1]\n",
    "        if video_type == 'left':\n",
    "            dot_s = 10  # [px] for painting DLC dots\n",
    "        else:\n",
    "            dot_s = 5\n",
    "\n",
    "    if save_video:\n",
    "    \n",
    "        rr = f'_{res}' if ens else ''\n",
    "        loc = (save_vids_here / \n",
    "        f'{eid}_{video_type}_frames_{frame_start}_{frame_stop}'\n",
    "        f'_lp_{lp}_ens_{ens}{rr}.mp4')\n",
    "\n",
    "        out = cv2.VideoWriter(str(loc),\n",
    "                              cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                              fps,\n",
    "                              size)  # put , 0 if grey scale\n",
    "\n",
    "    # writing stuff on frames\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    if video_type == 'left':\n",
    "        bottomLeftCornerOfText = (20, 1000)\n",
    "        fontScale = 4\n",
    "    else:\n",
    "        bottomLeftCornerOfText = (10, 500)\n",
    "        fontScale = 2\n",
    "\n",
    "    lineType = 2\n",
    "\n",
    "    # assign a color to each DLC point (now: all points red)\n",
    "    cmap = matplotlib.cm.get_cmap('Set1')\n",
    "    CR = np.arange(len(points)) / len(points)\n",
    "\n",
    "    block = np.ones((2 * dot_s, 2 * dot_s, 3))\n",
    "\n",
    "    # set start frame\n",
    "    cap.set(1, frame_start)\n",
    "\n",
    "    k = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        gray = frame\n",
    "\n",
    "        # print wheel angle\n",
    "        fontColor = (255, 255, 255)\n",
    "        Angle = round(wheel_pos[k], 2)\n",
    "        Time = round(Times[k], 3)\n",
    "        cv2.putText(gray,\n",
    "                    'Wheel angle: ' + str(Angle),\n",
    "                    bottomLeftCornerOfText,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "\n",
    "        a, b = bottomLeftCornerOfText\n",
    "        bottomLeftCornerOfText0 = (int(a * 10 + b / 2), b)\n",
    "        cv2.putText(gray,\n",
    "                    '  time: ' + str(Time),\n",
    "                    bottomLeftCornerOfText0,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "                    \n",
    "                    \n",
    "        bottomLeftCornerOfText1 = (a, b - 3* a)\n",
    "        cv2.putText(gray,\n",
    "                    'Frame: ' + str(Frames[k]),\n",
    "                    bottomLeftCornerOfText1,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        # print DLC dots\n",
    "        ll = 0\n",
    "        for point in points:\n",
    "\n",
    "            # Put point color legend\n",
    "            fontColor = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "            a, b = bottomLeftCornerOfText\n",
    "            if video_type == 'right':\n",
    "                bottomLeftCornerOfText2 = (a, a * 2 * (1 + ll))\n",
    "            else:\n",
    "                bottomLeftCornerOfText2 = (b, a * 2 * (1 + ll))\n",
    "            fontScale2 = fontScale / 4\n",
    "            cv2.putText(gray, point,\n",
    "                        bottomLeftCornerOfText2,\n",
    "                        font,\n",
    "                        fontScale2,\n",
    "                        fontColor,\n",
    "                        lineType)\n",
    "\n",
    "            if ens:\n",
    "                for XYs in XYss:\n",
    "\n",
    "                    X0 = XYs[point][0][k]\n",
    "                    Y0 = XYs[point][1][k]\n",
    "                    # transform for opencv?\n",
    "                    X = Y0\n",
    "                    Y = X0\n",
    "\n",
    "                    if not np.isnan(X) and not np.isnan(Y):\n",
    "                        col = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "                        # col = np.array([0, 0, 255]) # all points red\n",
    "                        X = X.astype(int)\n",
    "                        Y = Y.astype(int)\n",
    "                        gray[X - dot_s:X + dot_s, Y - \n",
    "                             dot_s:Y + dot_s] = block * col\n",
    "            if not ens:\n",
    "                X0 = XYs[point][0][k]\n",
    "                Y0 = XYs[point][1][k]\n",
    "                # transform for opencv?\n",
    "                X = Y0\n",
    "                Y = X0\n",
    "\n",
    "                if not np.isnan(X) and not np.isnan(Y):\n",
    "                    col = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "                    # col = np.array([0, 0, 255]) # all points red\n",
    "                    X = X.astype(int)\n",
    "                    Y = Y.astype(int)\n",
    "                    gray[X - dot_s:X + dot_s, Y - \n",
    "                         dot_s:Y + dot_s] = block * col            \n",
    "\n",
    "                \n",
    "            ll += 1\n",
    "\n",
    "        gray = gray[y0:y1, x0:x1]\n",
    "        if save_video:\n",
    "            out.write(gray)\n",
    "        #cv2.imshow('frame', gray)\n",
    "        #cv2.waitKey(1)\n",
    "        k += 1\n",
    "        if k == (frame_stop - frame_start) - 1:\n",
    "            break\n",
    "\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    print(eid, video_type, frame_stop, frame_start)\n",
    "    #return XYs, Times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid = 'c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee'\n",
    "video_type = 'left'\n",
    "frame_start = 1\n",
    "frame_stop = 10000\n",
    "lp=True\n",
    "save_video=True\n",
    "eye_zoom=False\n",
    "ens=False\n",
    "res = '128x102_128x128'\n",
    "masked=True\n",
    "paws_only=False\n",
    "smooth_dlc = False\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file paths\n",
    "\n",
    "save_vids_here = Path.home()\n",
    "\n",
    "alf_path = one.eid2path(eid)\n",
    "\n",
    "# Download a single video\n",
    "video_path = (alf_path / \n",
    "    f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4')\n",
    "\n",
    "if not os.path.isfile(video_path):\n",
    "    print('mp4 not found locally, downloading it ...')\n",
    "    video_path = one.load_dataset(eid,\n",
    "        f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4',\n",
    "        download_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LP, 128x102_128x128, left\n",
      "multi, paws:False, c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee\n",
      "Index(['nose_tip_x', 'nose_tip_y', 'nose_tip_likelihood', 'pupil_top_r_x',\n",
      "       'pupil_top_r_y', 'pupil_top_r_likelihood', 'pupil_right_r_x',\n",
      "       'pupil_right_r_y', 'pupil_right_r_likelihood', 'pupil_bottom_r_x',\n",
      "       'pupil_bottom_r_y', 'pupil_bottom_r_likelihood', 'pupil_left_r_x',\n",
      "       'pupil_left_r_y', 'pupil_left_r_likelihood', 'paw_l_x', 'paw_l_y',\n",
      "       'paw_l_likelihood', 'paw_r_x', 'paw_r_y', 'paw_r_likelihood',\n",
      "       'tube_top_x', 'tube_top_y', 'tube_top_likelihood', 'tube_bottom_x',\n",
      "       'tube_bottom_y', 'tube_bottom_likelihood', 'tongue_end_l_x',\n",
      "       'tongue_end_l_y', 'tongue_end_l_likelihood', 'tongue_end_r_x',\n",
      "       'tongue_end_r_y', 'tongue_end_r_likelihood'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Download LP traces and stamps\n",
    "Times = one.load_dataset(eid,f'alf/_ibl_{video_type}Camera.times.npy')\n",
    "\n",
    "cam = load_lp(eid, video_type, paws=False,\n",
    "        reso=res, flav='multi')\n",
    "\n",
    "print(cam.keys())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LP, 128x102_128x128, left\n",
      "multi, paws:False, c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee\n",
      "Index(['nose_tip_x', 'nose_tip_y', 'nose_tip_likelihood', 'pupil_top_r_x',\n",
      "       'pupil_top_r_y', 'pupil_top_r_likelihood', 'pupil_right_r_x',\n",
      "       'pupil_right_r_y', 'pupil_right_r_likelihood', 'pupil_bottom_r_x',\n",
      "       'pupil_bottom_r_y', 'pupil_bottom_r_likelihood', 'pupil_left_r_x',\n",
      "       'pupil_left_r_y', 'pupil_left_r_likelihood', 'paw_l_x', 'paw_l_y',\n",
      "       'paw_l_likelihood', 'paw_r_x', 'paw_r_y', 'paw_r_likelihood',\n",
      "       'tube_top_x', 'tube_top_y', 'tube_top_likelihood', 'tube_bottom_x',\n",
      "       'tube_bottom_y', 'tube_bottom_likelihood', 'tongue_end_l_x',\n",
      "       'tongue_end_l_y', 'tongue_end_l_likelihood', 'tongue_end_r_x',\n",
      "       'tongue_end_r_y', 'tongue_end_r_likelihood'],\n",
      "      dtype='object')\n",
      "c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee ,  left , fsp: 30.0 , #frames: 435336 , #stamps: 435336 , #frames - #stamps =  0\n",
      "frame start stop 1 10000\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "# get video info\n",
    "cap = cv2.VideoCapture(video_path.as_uri())\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(3)), int(cap.get(4)))  # size of windowin pixels?\n",
    "\n",
    "print(eid,\n",
    "        ', ',\n",
    "        video_type,\n",
    "        ', fsp:',\n",
    "        fps,\n",
    "        ', #frames:',\n",
    "        length,\n",
    "        ', #stamps:',\n",
    "        len(Times),\n",
    "        ', #frames - #stamps = ',\n",
    "        length - len(Times))\n",
    "\n",
    "# pick trial range for which to display stuff\n",
    "trials = one.load_object(eid, 'trials')\n",
    "\n",
    "print('frame start stop', frame_start, frame_stop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3000\n",
      "iteration 6000\n",
      "iteration 9000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load wheel\n",
    "'''\n",
    "\n",
    "wheel = one.load_object(eid, 'wheel')\n",
    "import brainbox.behavior.wheel as wh\n",
    "try:\n",
    "    pos, t = wh.interpolate_position(\n",
    "        wheel['timestamps'], wheel['position'], freq=1000)\n",
    "except BaseException:\n",
    "    pos, t = wh.interpolate_position(\n",
    "        wheel['times'], wheel['position'], freq=1000)\n",
    "\n",
    "w_start = find_nearest(t, Times[frame_start])\n",
    "w_stop = find_nearest(t, Times[frame_stop])\n",
    "\n",
    "# confine to interval\n",
    "pos_int = pos[w_start:w_stop]\n",
    "t_int = t[w_start:w_stop]\n",
    "\n",
    "# alignment of cam stamps and interpolated wheel stamps\n",
    "wheel_pos = []\n",
    "kk = 0\n",
    "for wt in Times[frame_start:frame_stop]:\n",
    "    wheel_pos.append(pos_int[find_nearest(t_int, wt)])\n",
    "    kk += 1\n",
    "    if kk % 3000 == 0:\n",
    "        print('iteration', kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LP related stuff\n",
    "'''\n",
    "# Trim and keep only frames of interest\n",
    "Times = Times[frame_start:frame_stop]\n",
    "Frames = np.arange(frame_start, frame_stop)\n",
    "\n",
    "# liklihood threshold\n",
    "l_thr = 0.9 if masked else -1\n",
    "\n",
    "# Get strings with keypoint names\n",
    "points = [x[:-2] for x in cam.keys() if x[-1] == 'x']\n",
    "\n",
    "if video_type != 'body':\n",
    "    try:\n",
    "        d = list(points)\n",
    "        d.remove('tube_top')\n",
    "        d.remove('tube_bottom')\n",
    "        points = d\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if paws_only:\n",
    "    p2 = deepcopy(points)\n",
    "    for point in p2:\n",
    "        if not 'paw' in point:\n",
    "            points.remove(point)            \n",
    "\n",
    "points = np.array(points)\n",
    "\n",
    "\n",
    "# Set values to nan if likelyhood is too low # for pqt: .to_numpy()\n",
    "XYs = {}\n",
    "for point in points:\n",
    "    x = np.ma.masked_where(\n",
    "        cam[point + '_likelihood'] < l_thr, cam[point + '_x'])\n",
    "    x = x.filled(np.nan)\n",
    "    y = np.ma.masked_where(\n",
    "        cam[point + '_likelihood'] < l_thr, cam[point + '_y'])\n",
    "    y = y.filled(np.nan)\n",
    "    XYs[point] = np.array(\n",
    "        [x[frame_start:frame_stop], y[frame_start:frame_stop]])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9997 is out of bounds for axis 0 with size 9997",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m fontColor \u001b[39m=\u001b[39m (\u001b[39m255\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m255\u001b[39m)\n\u001b[1;32m     64\u001b[0m Angle \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(wheel_pos[k], \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m Time \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(Times[k], \u001b[39m3\u001b[39m)\n\u001b[1;32m     66\u001b[0m cv2\u001b[39m.\u001b[39mputText(gray,\n\u001b[1;32m     67\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mWheel angle: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Angle),\n\u001b[1;32m     68\u001b[0m             bottomLeftCornerOfText,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m             fontColor,\n\u001b[1;32m     72\u001b[0m             lineType)\n\u001b[1;32m     74\u001b[0m a, b \u001b[39m=\u001b[39m bottomLeftCornerOfText\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9997 is out of bounds for axis 0 with size 9997"
     ]
    }
   ],
   "source": [
    "# Just for 3D testing\n",
    "# return XYs\n",
    "\n",
    "# Zoom at eye\n",
    "if eye_zoom:\n",
    "    pivot = np.nanmean(XYs['pupil_top_r'], axis=1)\n",
    "    x0 = int(pivot[0]) - 33\n",
    "    x1 = int(pivot[0]) + 33\n",
    "    y0 = int(pivot[1]) - 28\n",
    "    y1 = int(pivot[1]) + 38\n",
    "    size = (66, 66)\n",
    "    dot_s = 1  # [px] for painting DLC dots\n",
    "\n",
    "else:\n",
    "    x0 = 0\n",
    "    x1 = size[0]\n",
    "    y0 = 0\n",
    "    y1 = size[1]\n",
    "    if video_type == 'left':\n",
    "        dot_s = 10  # [px] for painting DLC dots\n",
    "    else:\n",
    "        dot_s = 5\n",
    "\n",
    "if save_video:\n",
    "\n",
    "    rr = f'_{res}' if ens else ''\n",
    "    loc = (save_vids_here / \n",
    "    f'{eid}_{video_type}_frames_{frame_start}_{frame_stop}'\n",
    "    f'_lp_{lp}_ens_{ens}{rr}.mp4')\n",
    "\n",
    "    out = cv2.VideoWriter(str(loc),\n",
    "                            cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                            fps,\n",
    "                            size)  # put , 0 if grey scale\n",
    "\n",
    "# writing stuff on frames\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "if video_type == 'left':\n",
    "    bottomLeftCornerOfText = (20, 1000)\n",
    "    fontScale = 4\n",
    "else:\n",
    "    bottomLeftCornerOfText = (10, 500)\n",
    "    fontScale = 2\n",
    "\n",
    "lineType = 2\n",
    "\n",
    "# assign a color to each DLC point (now: all points red)\n",
    "cmap = matplotlib.cm.get_cmap('Set1')\n",
    "CR = np.arange(len(points)) / len(points)\n",
    "\n",
    "block = np.ones((2 * dot_s, 2 * dot_s, 3))\n",
    "\n",
    "# set start frame\n",
    "cap.set(1, frame_start)\n",
    "\n",
    "k = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    gray = frame\n",
    "\n",
    "    # print wheel angle\n",
    "    fontColor = (255, 255, 255)\n",
    "    Angle = round(wheel_pos[k], 2)\n",
    "    Time = round(Times[k], 3)\n",
    "    cv2.putText(gray,\n",
    "                'Wheel angle: ' + str(Angle),\n",
    "                bottomLeftCornerOfText,\n",
    "                font,\n",
    "                fontScale / 2,\n",
    "                fontColor,\n",
    "                lineType)\n",
    "\n",
    "    a, b = bottomLeftCornerOfText\n",
    "    bottomLeftCornerOfText0 = (int(a * 10 + b / 2), b)\n",
    "    cv2.putText(gray,\n",
    "                '  time: ' + str(Time),\n",
    "                bottomLeftCornerOfText0,\n",
    "                font,\n",
    "                fontScale / 2,\n",
    "                fontColor,\n",
    "                lineType)\n",
    "                \n",
    "                \n",
    "    bottomLeftCornerOfText1 = (a, b - 3* a)\n",
    "    cv2.putText(gray,\n",
    "                'Frame: ' + str(Frames[k]),\n",
    "                bottomLeftCornerOfText1,\n",
    "                font,\n",
    "                fontScale / 2,\n",
    "                fontColor,\n",
    "                lineType)                    \n",
    "                \n",
    "                \n",
    "\n",
    "    # print DLC dots\n",
    "    ll = 0\n",
    "    for point in points:\n",
    "\n",
    "        # Put point color legend\n",
    "        fontColor = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "        a, b = bottomLeftCornerOfText\n",
    "        if video_type == 'right':\n",
    "            bottomLeftCornerOfText2 = (a, a * 2 * (1 + ll))\n",
    "        else:\n",
    "            bottomLeftCornerOfText2 = (b, a * 2 * (1 + ll))\n",
    "        fontScale2 = fontScale / 4\n",
    "        cv2.putText(gray, point,\n",
    "                    bottomLeftCornerOfText2,\n",
    "                    font,\n",
    "                    fontScale2,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "\n",
    "        if ens:\n",
    "            for XYs in XYss:\n",
    "\n",
    "                X0 = XYs[point][0][k]\n",
    "                Y0 = XYs[point][1][k]\n",
    "                # transform for opencv?\n",
    "                X = Y0\n",
    "                Y = X0\n",
    "\n",
    "                if not np.isnan(X) and not np.isnan(Y):\n",
    "                    col = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "                    # col = np.array([0, 0, 255]) # all points red\n",
    "                    X = X.astype(int)\n",
    "                    Y = Y.astype(int)\n",
    "                    gray[X - dot_s:X + dot_s, Y - \n",
    "                            dot_s:Y + dot_s] = block * col\n",
    "            \n",
    "            \n",
    "        if not ens:\n",
    "            X0 = XYs[point][0][k]\n",
    "            Y0 = XYs[point][1][k]\n",
    "            # transform for opencv?\n",
    "            X = Y0\n",
    "            Y = X0\n",
    "\n",
    "            if not np.isnan(X) and not np.isnan(Y):\n",
    "                col = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "                # col = np.array([0, 0, 255]) # all points red\n",
    "                X = X.astype(int)\n",
    "                Y = Y.astype(int)\n",
    "                gray[X - dot_s:X + dot_s, Y - \n",
    "                        dot_s:Y + dot_s] = block * col            \n",
    "\n",
    "            \n",
    "        ll += 1\n",
    "\n",
    "    gray = gray[y0:y1, x0:x1]\n",
    "    if save_video:\n",
    "        out.write(gray)\n",
    "    #cv2.imshow('frame', gray)\n",
    "    #cv2.waitKey(1)\n",
    "    k += 1\n",
    "    if k == (frame_stop - frame_start) - 1:\n",
    "        break\n",
    "\n",
    "if save_video:\n",
    "    out.release()\n",
    "cap.release()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "print(eid, video_type, frame_stop, frame_start)\n",
    "#return XYs, Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LP, 128x102_128x128, left\n",
      "multi, paws:False, c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee\n",
      "Index(['nose_tip_x', 'nose_tip_y', 'nose_tip_likelihood', 'pupil_top_r_x',\n",
      "       'pupil_top_r_y', 'pupil_top_r_likelihood', 'pupil_right_r_x',\n",
      "       'pupil_right_r_y', 'pupil_right_r_likelihood', 'pupil_bottom_r_x',\n",
      "       'pupil_bottom_r_y', 'pupil_bottom_r_likelihood', 'pupil_left_r_x',\n",
      "       'pupil_left_r_y', 'pupil_left_r_likelihood', 'paw_l_x', 'paw_l_y',\n",
      "       'paw_l_likelihood', 'paw_r_x', 'paw_r_y', 'paw_r_likelihood',\n",
      "       'tube_top_x', 'tube_top_y', 'tube_top_likelihood', 'tube_bottom_x',\n",
      "       'tube_bottom_y', 'tube_bottom_likelihood', 'tongue_end_l_x',\n",
      "       'tongue_end_l_y', 'tongue_end_l_likelihood', 'tongue_end_r_x',\n",
      "       'tongue_end_r_y', 'tongue_end_r_likelihood'],\n",
      "      dtype='object')\n",
      "c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee ,  left , fsp: 30.0 , #frames: 435336 , #stamps: 435336 , #frames - #stamps =  0\n",
      "frame start stop 1 10000\n",
      "iteration 3000\n",
      "iteration 6000\n",
      "iteration 9000\n",
      "c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee left 10000 1\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "session_eid = 'c4a4d9d8-a5f6-48b6-b4b6-a23f3f76e9ee'\n",
    "# session_eid = '7330f879-8dfc-4344-af84-cd422199bddc'\n",
    "# Viewer(eid, video_type, frame_start, frame_stop, save_video=True, \n",
    "#            eye_zoom=False, lp=False, ens=False,\n",
    "#            res = '128x102_128x128', masked=True, paws_only=False,\n",
    "#            smooth_dlc = False)\n",
    "Viewer(session_eid, 'left', 1, 10000, lp=True)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21541729b5da47a594818561e91cb4175a7e192d68b7cc4221509f43b2f902b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
