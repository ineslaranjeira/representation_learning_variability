{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fd8a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/miniconda3/envs/iblenv/lib/python3.9/site-packages/one/api.py:1644: UserWarning: Newer cache tables require ONE version 2.10 or greater\n",
      "  warnings.warn(f'Newer cache tables require ONE version {min_version} or greater')\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os  # ,fnmatch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from brainbox.io.one import SessionLoader\n",
    "from ibldsp.smooth import smooth_interpolate_savgol  # Ines commented out; need to update iblenv to make this work\n",
    "from one.api import ONE\n",
    "\n",
    "# one = ONE()\n",
    "one = ONE(base_url='https://alyx.internationalbrainlab.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8edfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def load_pose(eid, cam, smoothed=False, manual=True, use_lp=True):\n",
    "\n",
    "    '''\n",
    "    cam in left, right, body \n",
    "    '''\n",
    "\n",
    "    if manual:\n",
    "        pth = one.eid2path(eid)\n",
    "        if use_lp:\n",
    "            d = pd.read_parquet(pth / 'alf' / f'_ibl_{cam}Camera.lightningPose.pqt')\n",
    "        else:\n",
    "            d = pd.read_parquet(pth / 'alf' / f'_ibl_{cam}Camera.dlc.pqt')\n",
    "        d['times'] = np.load(one.eid2path(eid) / 'alf'\n",
    "                    / f'_ibl_{cam}Camera.times.npy')\n",
    "                    \n",
    "        ls = [len(d[x]) for x in d]\n",
    "        if not all(ls == np.mean(ls)):\n",
    "            lsd = {x:len(d[x]) for x in d}\n",
    "            print(f'length mismatch: {lsd}')\n",
    "            print(eid, cam)\n",
    "            print('cutting times')\n",
    "            d['times'] = d['times'][:ls[0]]            \n",
    "\n",
    "    else:\n",
    "        # load DLC\n",
    "        sess_loader = SessionLoader(one, eid)\n",
    "        sess_loader.load_pose(views=[cam])\n",
    "        d = sess_loader.pose[f'{cam}Camera']\n",
    "    \n",
    "    if smoothed:\n",
    "        print('smoothing dlc traces')\n",
    "        window = 13 if cam == 'right' else 7\n",
    "        sers = [x for x in d.keys() if (x[-1] in ['x','y'])]# and 'paw' in x\n",
    "        for ser in sers:\n",
    "            d[ser] = smooth_interpolate_savgol(\n",
    "                d[ser].to_numpy(),\n",
    "                window=window,order=3, interp_kind='linear')   \n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Viewer(eid, video_type, frame_start, frame_stop, save_video=True, \n",
    "           eye_zoom=False, lp=False, masked=True, paws_only=False,\n",
    "           smooth_dlc = False\n",
    "          ):\n",
    "           \n",
    "    '''\n",
    "    eid: session id, e.g. '3663d82b-f197-4e8b-b299-7b803a155b84'\n",
    "    video_type: one of 'left', 'right', 'body'\n",
    "    save_video: video is saved this local folder\n",
    "\n",
    "    Example usage to view and save labeled video with wheel angle:\n",
    "    Viewer('3663d82b-f197-4e8b-b299-7b803a155b84', 'left', [5,7])\n",
    "\n",
    "    '''\n",
    "\n",
    "    save_vids_here = Path.home()/'Output LP'\n",
    "\n",
    "\n",
    "    alf_path = one.eid2path(eid)\n",
    "\n",
    "    # Download a single video\n",
    "    video_path = (alf_path / \n",
    "        f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4')\n",
    "    \n",
    "    if not os.path.isfile(video_path):\n",
    "        print('mp4 not found locally, downloading it ...')\n",
    "        video_path = one.load_dataset(eid,\n",
    "            f'raw_video_data/_iblrig_{video_type}Camera.raw.mp4',\n",
    "            download_only=True)\n",
    "\n",
    "\n",
    "    # Download DLC traces and stamps\n",
    "    Times = one.load_dataset(eid,f'alf/_ibl_{video_type}Camera.times.npy')\n",
    "\n",
    "    print('loading pose')\n",
    "    cam = load_pose(eid, video_type, smoothed=smooth_dlc, use_lp=lp)\n",
    "                                                      \n",
    "    # get video info\n",
    "    cap = cv2.VideoCapture(video_path.as_uri())\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    size = (int(cap.get(3)), int(cap.get(4)))\n",
    "\n",
    "    print(eid,\n",
    "          ', ',\n",
    "          video_type,\n",
    "          ', fsp:',\n",
    "          fps,\n",
    "          ', #frames:',\n",
    "          length,\n",
    "          ', #stamps:',\n",
    "          len(Times),\n",
    "          ', #frames - #stamps = ',\n",
    "          length - len(Times))\n",
    "\n",
    "    # pick trial range for which to display stuff\n",
    "    trials = one.load_object(eid, 'trials')\n",
    "\n",
    "    print('frame start stop', frame_start, frame_stop)\n",
    "\n",
    "    '''\n",
    "    load wheel\n",
    "    '''\n",
    "\n",
    "    wheel = one.load_object(eid, 'wheel')\n",
    "    import brainbox.behavior.wheel as wh\n",
    "    try:\n",
    "        pos, t = wh.interpolate_position(\n",
    "            wheel['timestamps'], wheel['position'], freq=1000)\n",
    "    except BaseException:\n",
    "        pos, t = wh.interpolate_position(\n",
    "            wheel['times'], wheel['position'], freq=1000)\n",
    "\n",
    "    w_start = find_nearest(t, Times[frame_start])\n",
    "    w_stop = find_nearest(t, Times[frame_stop])\n",
    "\n",
    "    # confine to interval\n",
    "    pos_int = pos[w_start:w_stop]\n",
    "    t_int = t[w_start:w_stop]\n",
    "\n",
    "    # alignment of cam stamps and interpolated wheel stamps\n",
    "    wheel_pos = []\n",
    "    kk = 0\n",
    "    for wt in Times[frame_start:frame_stop]:\n",
    "        wheel_pos.append(pos_int[find_nearest(t_int, wt)])\n",
    "        kk += 1\n",
    "        if kk % 3000 == 0:\n",
    "            print('iteration', kk)\n",
    "\n",
    "    '''\n",
    "    DLC related stuff\n",
    "    '''\n",
    "    Times = Times[frame_start:frame_stop]\n",
    "    Frames = np.arange(frame_start, frame_stop)\n",
    "    \n",
    "    \n",
    "    # liklihood threshold\n",
    "    l_thr = 0.9 if masked else -1\n",
    "    # l_thr = 0 if masked else -1  # Ines added\n",
    "\n",
    "    points = [x[:-2] for x in cam.keys() if x[-1] == 'x']\n",
    "\n",
    "    if video_type != 'body':\n",
    "        try:\n",
    "            d = list(points)\n",
    "            d.remove('tube_top')\n",
    "            d.remove('tube_bottom')\n",
    "            points = d\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if paws_only:\n",
    "        p2 = deepcopy(points)\n",
    "        for point in p2:\n",
    "            if not 'paw' in point:\n",
    "                points.remove(point)            \n",
    "\n",
    "    points = np.array(points)        \n",
    "        \n",
    "    # Set values to nan if likelyhood is too low # for pqt: .to_numpy()\n",
    "    XYs = {}\n",
    "    zscores = {}  # Ines added\n",
    "    for point in points:\n",
    "        x = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < l_thr, cam[point + '_x'])\n",
    "        x = x.filled(np.nan)\n",
    "        y = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < l_thr, cam[point + '_y'])\n",
    "        y = y.filled(np.nan)\n",
    "        XYs[point] = np.array(\n",
    "            [x[frame_start:frame_stop], y[frame_start:frame_stop]])    \n",
    "        # if 'pupil' in point or 'paw' in point:    \n",
    "        #     zsc = np.ma.masked_where(\n",
    "        #         cam[point + '_likelihood'] < l_thr, cam[point + '_zscore'])\n",
    "        #     zsc = zsc.filled(np.nan)\n",
    "        #     zscores[point] = np.array(\n",
    "        #         zsc[frame_start:frame_stop])\n",
    "                   \n",
    "        \n",
    "\n",
    "    # Just for 3D testing\n",
    "    # return XYs\n",
    "\n",
    "    # Zoom at eye\n",
    "    if eye_zoom:\n",
    "        pivot = np.nanmean(XYs['pupil_top_r'], axis=1)\n",
    "        x0 = int(pivot[0]) - 33\n",
    "        x1 = int(pivot[0]) + 33\n",
    "        y0 = int(pivot[1]) - 28\n",
    "        y1 = int(pivot[1]) + 38\n",
    "        size = (66, 66)\n",
    "        dot_s = 1  # [px] for painting DLC dots\n",
    "\n",
    "    else:\n",
    "        x0 = 0\n",
    "        x1 = size[0]\n",
    "        y0 = 0\n",
    "        y1 = size[1]\n",
    "        if video_type == 'left':\n",
    "            dot_s = 10  # [px] for painting DLC dots\n",
    "        else:\n",
    "            dot_s = 5\n",
    "\n",
    "    if save_video:\n",
    "    \n",
    "        loc = (save_vids_here / \n",
    "        f'{eid}_{video_type}_frames_{frame_start}_{frame_stop}'\n",
    "        f'_lp_{lp}.mp4')\n",
    "\n",
    "        out = cv2.VideoWriter(str(loc),\n",
    "                              cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                              fps,\n",
    "                              size)  # put , 0 if grey scale\n",
    "\n",
    "    # writing stuff on frames\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    if video_type == 'left':\n",
    "        bottomLeftCornerOfText = (20, 1000)\n",
    "        fontScale = 4\n",
    "    else:\n",
    "        bottomLeftCornerOfText = (10, 500)\n",
    "        fontScale = 2\n",
    "\n",
    "    lineType = 2\n",
    "\n",
    "    # assign a color to each DLC point (now: all points red)\n",
    "    cmap = matplotlib.cm.get_cmap('Set1')\n",
    "    CR = np.arange(len(points)) / len(points)\n",
    "\n",
    "    block = np.ones((2 * dot_s, 2 * dot_s, 3))\n",
    "\n",
    "    # set start frame\n",
    "    cap.set(1, frame_start)\n",
    "\n",
    "    k = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        gray = frame\n",
    "\n",
    "        # print wheel angle\n",
    "        fontColor = (255, 255, 255)\n",
    "        Angle = round(wheel_pos[k], 2)\n",
    "        Time = round(Times[k], 3)\n",
    "        cv2.putText(gray,\n",
    "                    'Wheel angle: ' + str(Angle),\n",
    "                    bottomLeftCornerOfText,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "\n",
    "        a, b = bottomLeftCornerOfText\n",
    "        bottomLeftCornerOfText0 = (int(a * 10 + b / 2), b)\n",
    "        cv2.putText(gray,\n",
    "                    '  time: ' + str(Time),\n",
    "                    bottomLeftCornerOfText0,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)\n",
    "                    \n",
    "                    \n",
    "        bottomLeftCornerOfText1 = (a, b - 3* a)\n",
    "        cv2.putText(gray,\n",
    "                    'Frame: ' + str(Frames[k]),\n",
    "                    bottomLeftCornerOfText1,\n",
    "                    font,\n",
    "                    fontScale / 2,\n",
    "                    fontColor,\n",
    "                    lineType)                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        # print DLC dots\n",
    "        ll = 0\n",
    "        for point in points:\n",
    "\n",
    "            # Put point color legend\n",
    "            fontColor = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "            a, b = bottomLeftCornerOfText\n",
    "            if video_type == 'right':\n",
    "                bottomLeftCornerOfText2 = (a, a * 2 * (1 + ll))\n",
    "            else:\n",
    "                bottomLeftCornerOfText2 = (b, a * 2 * (1 + ll))\n",
    "            fontScale2 = fontScale / 4\n",
    "            cv2.putText(gray, point,\n",
    "                        bottomLeftCornerOfText2,\n",
    "                        font,\n",
    "                        fontScale2,\n",
    "                        fontColor,\n",
    "                        lineType)              \n",
    "\n",
    "            X0 = XYs[point][0][k]\n",
    "            Y0 = XYs[point][1][k]\n",
    "            # if 'pupil' in point or 'paw' in point:\n",
    "            #     ZSCORE = zscores[point][k]  # Ines added\n",
    "            # transform for opencv?\n",
    "            X = Y0\n",
    "            Y = X0\n",
    "\n",
    "            if not np.isnan(X) and not np.isnan(Y):\n",
    "                col = (np.array([cmap(CR[ll])]) * 255)[0][:3]\n",
    "                # col = np.array([0, 0, 255]) # all points red\n",
    "                # if 'pupil' in point or 'paw' in point:\n",
    "                #     # Ines added\n",
    "                #     if ZSCORE > .5:\n",
    "                #         col = np.array([0, 0, 255]) # red\n",
    "                #     elif ZSCORE < .1:\n",
    "                #         col = np.array([0, 255, 0]) # green\n",
    "                #     elif .1 <= ZSCORE <= .5:\n",
    "                #         col = np.array([0, 255, 255]) # yellow\n",
    "                X = X.astype(int)\n",
    "                Y = Y.astype(int)\n",
    "                gray[X - dot_s:X + dot_s, Y - \n",
    "                     dot_s:Y + dot_s] = block * col            \n",
    "\n",
    "            ll += 1\n",
    "\n",
    "        gray = gray[y0:y1, x0:x1]\n",
    "        if save_video:\n",
    "            out.write(gray)\n",
    "        k += 1\n",
    "        if k == (frame_stop - frame_start) - 1:\n",
    "            break\n",
    "\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    file_path\n",
    "    print(eid, video_type, frame_start, frame_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24689189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp4 not found locally, downloading it ...\n",
      "Downloading: /home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_024/2020-06-08/001/raw_video_data/_iblrig_leftCamera.raw.d57b10ad-2b64-49a8-a4dc-39004adf55ae.mp4 Bytes: 10286579343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9810.046523094177/9810.046523094177 [26:32<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pose\n",
      "8207abc6-6b23-4762-92b4-82e05bed5143 ,  left , fsp: 60.0 , #frames: 444776 , #stamps: 444776 , #frames - #stamps =  0\n",
      "frame start stop 5000 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_024/2020-06-08/001/alf/_ibl_wheel.timestamps.npy: 100%|██████████| 5.39M/5.39M [00:03<00:00, 1.78MB/s]\n",
      "/home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_024/2020-06-08/001/alf/_ibl_wheel.position.npy: 100%|██████████| 5.39M/5.39M [00:02<00:00, 1.89MB/s]\n",
      "/tmp/ipykernel_54901/190198525.py:237: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = matplotlib.cm.get_cmap('Set1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8207abc6-6b23-4762-92b4-82e05bed5143 left 5000 7000\n",
      "File '/home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_024/2020-06-08/001/raw_video_data/_iblrig_leftCamera.raw.mp4' deleted successfully.\n",
      "mp4 not found locally, downloading it ...\n",
      "Downloading: /home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_025/2020-07-26/001/raw_video_data/_iblrig_leftCamera.raw.a9008393-5229-4485-9ac5-67edf0aa82fe.mp4 Bytes: 3440720104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3281.3263931274414/3281.3263931274414 [09:16<00:00,  5.90it/s]\n",
      "/home/ines/Downloads/ONE/alyx.internationalbrainlab.org/zadorlab/Subjects/CSH_ZAD_025/2020-07-26/001/alf/_ibl_leftCamera.times.npy: 100%|██████████| 2.23M/2.23M [00:01<00:00, 1.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pose\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (278361) does not match length of index (278412)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m file_path \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mstr\u001b[39m(eid)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_left_frames_5000_7000_lp_False.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mViewer\u001b[49m\u001b[43m(\u001b[49m\u001b[43meid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Delete video\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     video_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(one\u001b[38;5;241m.\u001b[39meid2path(eid)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raw_video_data/_iblrig_leftCamera.raw.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36mViewer\u001b[0;34m(eid, video_type, frame_start, frame_stop, save_video, eye_zoom, lp, masked, paws_only, smooth_dlc)\u001b[0m\n\u001b[1;32m     82\u001b[0m Times \u001b[38;5;241m=\u001b[39m one\u001b[38;5;241m.\u001b[39mload_dataset(eid,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malf/_ibl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCamera.times.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading pose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m cam \u001b[38;5;241m=\u001b[39m \u001b[43mload_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43meid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmoothed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmooth_dlc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_lp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# get video info\u001b[39;00m\n\u001b[1;32m     88\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path\u001b[38;5;241m.\u001b[39mas_uri())\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mload_pose\u001b[0;34m(eid, cam, smoothed, manual, use_lp)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     d \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(pth \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ibl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCamera.dlc.pqt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(one\u001b[38;5;241m.\u001b[39meid2path(eid) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ibl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCamera.times.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m ls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(d[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m d]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(ls \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ls)):\n",
      "File \u001b[0;32m~/miniconda3/envs/iblenv/lib/python3.9/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/iblenv/lib/python3.9/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/iblenv/lib/python3.9/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/iblenv/lib/python3.9/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (278361) does not match length of index (278412)"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "ext_qc_path = '/home/ines/repositories/representation_learning_variability/Video and wheel/Video QC/'\n",
    "os.chdir(ext_qc_path)\n",
    "ext_qc = pickle.load(open(ext_qc_path + \"dlc_left_extended_qc\", \"rb\"))\n",
    "use_qc = ext_qc.loc[ext_qc['task'].isin(['PASS', 'WARNING'])]\n",
    "\n",
    "psth_df = pickle.load(open(ext_qc_path + \"dlc_left_extended_psth\", \"rb\"))\n",
    "lick_custom = pickle.load(open(ext_qc_path + \"dlc_left_extended_lick\", \"rb\"))\n",
    "\n",
    "use_filter = lick_custom.loc[(lick_custom['dlcLeft'].isin(['FAIL', 'CRITICAL', np.nan])) &\n",
    "                            (lick_custom['ratio']>5) &\n",
    "                            (lick_custom['miss_lick_count']<100)]\n",
    "eids = use_filter['eid'].unique()\n",
    "files = os.listdir(Path.home()/'Output LP')\n",
    "for e, eid in enumerate(eids[62:]):\n",
    "    file_path =  str(eid)+'_left_frames_5000_7000_lp_False.mp4'\n",
    "    \n",
    "    if file_path not in files:\n",
    "        #try:\n",
    "        Viewer(eid, 'left', 5000, 7000, lp=False)\n",
    "        # Delete video\n",
    "        video_file = str(one.eid2path(eid)) + '/raw_video_data/_iblrig_leftCamera.raw.mp4'\n",
    "        try: \n",
    "            os.remove(video_file)\n",
    "            print(f\"File '{video_file}' deleted successfully.\")\n",
    "        except:\n",
    "            print(f\"Could not delete '{video_file}' file.\")\n",
    "        # except:\n",
    "        #     print('Failed to plot ' + str(eid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "21541729b5da47a594818561e91cb4175a7e192d68b7cc4221509f43b2f902b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
