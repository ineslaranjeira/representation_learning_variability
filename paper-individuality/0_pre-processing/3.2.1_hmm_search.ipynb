{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5452caff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:2025-09-22 13:04:31,382:jax._src.xla_bridge:444: Jax plugin configuration error: Exception when calling jax_plugins.xla_cuda12.initialize()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ines/miniconda3/envs/iblenv/lib/python3.10/site-packages/jax/_src/xla_bridge.py\", line 442, in discover_pjrt_plugins\n",
      "    plugin_module.initialize()\n",
      "  File \"/home/ines/miniconda3/envs/iblenv/lib/python3.10/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 324, in initialize\n",
      "    _check_cuda_versions(raise_on_first_error=True)\n",
      "  File \"/home/ines/miniconda3/envs/iblenv/lib/python3.10/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 281, in _check_cuda_versions\n",
      "    local_device_count = cuda_versions.cuda_device_count()\n",
      "RuntimeError: jaxlib/cuda/versions_helpers.cc:113: operation cuInit(0) failed: CUDA_ERROR_NO_DEVICE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1\"\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import time\n",
    "import jax\n",
    "from jax import devices\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from scipy.stats import zscore\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from dynamax.hidden_markov_model import LinearAutoregressiveHMM, PoissonHMM\n",
    "from dynamax.hidden_markov_model import PoissonHMM \n",
    "\n",
    "# Get my functions\n",
    "from functions import idxs_from_files, cross_validate_poismodel, cross_validate_armodel, compute_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e817482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" GRID SEARCH FUNCTIONS \"\"\"\n",
    "\n",
    "# Function to perform grid search for a single session\n",
    "def grid_search_versatile(id, var_interest, zsc, fixed_states, truncate,\n",
    "                          params, sticky, save_path, data_path, num_train_batches, method, fit_method):\n",
    "    print(params)\n",
    "    print(jax.devices())\n",
    "    # Time job\n",
    "    start = time.time()\n",
    "    \n",
    "    # Load mouse/session data\n",
    "    mouse_name, session = id\n",
    "    filename = data_path + \"design_matrix_\" + str(session) + '_'  + mouse_name\n",
    "    original_design_matrix = pd.read_parquet(filename)\n",
    "\n",
    "    # Zscore if needed (paws)\n",
    "    if zsc == True:\n",
    "      array_matrix = zscore(np.array(original_design_matrix), axis=0, nan_policy='omit')\n",
    "    else:\n",
    "      array_matrix = np.array(original_design_matrix)\n",
    "\n",
    "    # Remove NaNs\n",
    "    filtered_matrix = array_matrix[~np.isnan(array_matrix).any(axis=1)]\n",
    "    keys = np.where(original_design_matrix.keys().isin(var_interest))\n",
    "    if truncate:\n",
    "        design_matrix = filtered_matrix[:100000, keys]  # Truncate session\n",
    "    else:\n",
    "        design_matrix = filtered_matrix[:, keys] \n",
    "    \n",
    "    design_matrix = np.reshape(design_matrix,(np.shape(design_matrix)[0], np.shape(design_matrix)[2]))\n",
    "\n",
    "    fit_id = str(mouse_name + session)\n",
    "\n",
    "    print(f\"Fitting session {fit_id}...\")\n",
    "\n",
    "    num_timesteps = np.shape(design_matrix)[0]\n",
    "    emission_dim = np.shape(design_matrix)[1]\n",
    "    shortened_array = np.array(design_matrix[:(num_timesteps // num_train_batches) * num_train_batches])\n",
    "    train_emissions = jnp.stack(jnp.split(shortened_array, num_train_batches))\n",
    "\n",
    "    # Initialize result containers\n",
    "    all_lls, all_baseline_lls = defaultdict(dict), defaultdict(dict)\n",
    "    all_init_params, all_fit_params = defaultdict(dict), defaultdict(dict)\n",
    "\n",
    "    if var_interest == ['Lick count']:\n",
    "        num_states, _, kappas = params\n",
    "        if fixed_states:\n",
    "            # Grid search\n",
    "            for kappa in kappas:\n",
    "                test_poishmm = PoissonHMM(num_states, emission_dim, transition_matrix_stickiness=kappa)\n",
    "                all_val_lls, fit_params, init_params, baseline_lls = cross_validate_poismodel(test_poishmm, jr.PRNGKey(0),\n",
    "                                                                                            train_emissions, num_train_batches, fit_method, num_iters=100)\n",
    "\n",
    "                all_lls[kappa] = all_val_lls\n",
    "                all_baseline_lls[kappa] = baseline_lls\n",
    "                all_init_params[kappa] = init_params\n",
    "                all_fit_params[kappa] = fit_params\n",
    "        else:\n",
    "            for state in num_states:\n",
    "                # Grid search\n",
    "                for kappa in kappas:\n",
    "                    test_poishmm = PoissonHMM(state, emission_dim, transition_matrix_stickiness=kappa)\n",
    "                    all_val_lls, fit_params, init_params, baseline_lls = cross_validate_poismodel(test_poishmm, jr.PRNGKey(0),\n",
    "                                                                                               train_emissions, num_train_batches, fit_method, num_iters=100)\n",
    "\n",
    "                    all_lls[state][kappa] = all_val_lls\n",
    "                    all_baseline_lls[state][kappa] = baseline_lls\n",
    "                    all_init_params[state][kappa] = init_params\n",
    "                    all_fit_params[state][kappa] = fit_params\n",
    "\n",
    "    else:\n",
    "        num_states, all_num_lags, kappas = params\n",
    "        if fixed_states:\n",
    "            # Grid search\n",
    "            for lag in all_num_lags:\n",
    "                for kappa in kappas:\n",
    "                    test_arhmm = LinearAutoregressiveHMM(num_states, emission_dim, num_lags=lag, transition_matrix_stickiness=kappa)\n",
    "                    my_inputs = compute_inputs(shortened_array, lag, emission_dim)\n",
    "                    train_inputs = jnp.stack(jnp.split(my_inputs, num_train_batches))\n",
    "\n",
    "                    all_val_lls, fit_params, init_params, baseline_lls = cross_validate_armodel(\n",
    "                        test_arhmm, jr.PRNGKey(0), train_emissions, train_inputs, method, num_train_batches, fit_method\n",
    "                    )\n",
    "\n",
    "                    all_lls[lag][kappa] = all_val_lls\n",
    "                    all_baseline_lls[lag][kappa] = baseline_lls\n",
    "                    all_init_params[lag][kappa] = init_params\n",
    "                    all_fit_params[lag][kappa] = fit_params\n",
    "        else:\n",
    "            # Grid search\n",
    "            for state in num_states:\n",
    "                for lag in all_num_lags:\n",
    "                    for kappa in kappas:\n",
    "                        test_arhmm = LinearAutoregressiveHMM(state, emission_dim, num_lags=lag, transition_matrix_stickiness=kappa)\n",
    "                        my_inputs = compute_inputs(shortened_array, lag, emission_dim)\n",
    "                        train_inputs = jnp.stack(jnp.split(my_inputs, num_train_batches))\n",
    "\n",
    "                        all_val_lls, fit_params, init_params, baseline_lls = cross_validate_armodel(\n",
    "                            test_arhmm, jr.PRNGKey(0), train_emissions, train_inputs, method, num_train_batches, fit_method\n",
    "                        )\n",
    "\n",
    "                        all_lls[state][lag][kappa] = all_val_lls\n",
    "                        all_baseline_lls[state][lag][kappa] = baseline_lls\n",
    "                        all_init_params[state][lag][kappa] = init_params\n",
    "                        all_fit_params[state][lag][kappa] = fit_params\n",
    "\n",
    "    # Save results\n",
    "    mouse_results = all_lls, all_baseline_lls, all_init_params, all_fit_params, design_matrix, params\n",
    "    result_filename = os.path.join(save_path, f\"{'best_sticky' if sticky else 'best'}_results_{var_interest[0]}_{fit_id}\")\n",
    "    with open(result_filename, \"wb\") as f:\n",
    "        pickle.dump(mouse_results, f)\n",
    "\n",
    "    print(f\"Session {fit_id} completed.\")\n",
    "    print(\"Time:\", time.time() - start)\n",
    "    del mouse_results, all_lls, all_baseline_lls, all_init_params, all_fit_params\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Main function for parallel processing\n",
    "def run_grid_search_parallel(idxs, var_interest, zsc, fixed_states, truncate, params, sticky,\n",
    "                             save_path, data_path, num_train_batches, method, fit_method, n_jobs):\n",
    "\n",
    "    # Create folder where to dump data\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(save_path)\n",
    "   \n",
    "    # Identify sessions to process\n",
    "    sessions_to_process = []\n",
    "    for m, mat in enumerate(idxs):\n",
    "        mouse_name = mat[37:]\n",
    "        session = mat[:36]\n",
    "        fit_id = str(mouse_name + session)\n",
    "        result_filename = os.path.join(save_path, f\"{'best_sticky' if sticky else 'best'}_results_{var_interest[0]}_{fit_id}\")\n",
    "        if not os.path.exists(result_filename):\n",
    "            sessions_to_process.append((mouse_name, session))\n",
    "    # sessions_to_process = sessions_to_process\n",
    "\n",
    "    print(f\"Found {len(sessions_to_process)} sessions to process.\")\n",
    "\n",
    "    # Run grid search in parallel\n",
    "    Parallel(n_jobs=n_jobs)(\n",
    "        delayed(grid_search_versatile)(\n",
    "            id, var_interest, zsc,\n",
    "            fixed_states, truncate, params, sticky, save_path, data_path, num_train_batches, method, fit_method\n",
    "        ) for id in sessions_to_process\n",
    "    )\n",
    "\n",
    "# Main function for parallel processing\n",
    "def run_grid_search_serial(idxs, var_interest, zsc, fixed_states, truncate, params, sticky,\n",
    "                             save_path, data_path, num_train_batches, method, fit_method):\n",
    "\n",
    "    # Create folder where to dump data\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(save_path)\n",
    "   \n",
    "    # Identify sessions to process\n",
    "    sessions_to_process = []\n",
    "    for m, mat in enumerate(idxs):\n",
    "        mouse_name = mat[37:]\n",
    "        session = mat[:36]\n",
    "        fit_id = str(mouse_name + session)\n",
    "        result_filename = os.path.join(save_path, f\"{'best_sticky' if sticky else 'best'}_results_{var_interest[0]}_{fit_id}\")\n",
    "        if not os.path.exists(result_filename):\n",
    "            sessions_to_process.append((mouse_name, session))\n",
    "    # sessions_to_process = sessions_to_process\n",
    "\n",
    "    print(f\"Found {len(sessions_to_process)} sessions to process.\")\n",
    "    \n",
    "    # Run grid search in series\n",
    "    for m, mat in enumerate(sessions_to_process):\n",
    "\n",
    "        grid_search_versatile(\n",
    "            mat, var_interest, zsc,\n",
    "            fixed_states, truncate, params, sticky, save_path, data_path, num_train_batches, method, fit_method\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a8d62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 sessions to process.\n",
      "(2, [1, 10, 20, 30], [0, 5, 50])\n",
      "[CpuDevice(id=0)]\n",
      "Fitting session UCLA005d57df551-6dcb-4242-9c72-b806cff5613a...\n",
      "Session UCLA005d57df551-6dcb-4242-9c72-b806cff5613a completed.\n",
      "Time: 228.4250042438507\n",
      "(2, [1, 10, 20, 30], [0, 5, 50])\n",
      "[CpuDevice(id=0)]\n",
      "Fitting session SWC_0651425bd6f-c625-4f6a-b237-dc5bcfc42c87...\n",
      "Session SWC_0651425bd6f-c625-4f6a-b237-dc5bcfc42c87 completed.\n",
      "Time: 248.066241979599\n",
      "(2, [1, 10, 20, 30], [0, 5, 50])\n",
      "[CpuDevice(id=0)]\n",
      "Fitting session UCLA0335455a21c-1be7-4cae-ae8e-8853a8d5f55e...\n",
      "Session UCLA0335455a21c-1be7-4cae-ae8e-8853a8d5f55e completed.\n",
      "Time: 211.64462995529175\n",
      "(2, [1, 10, 20, 30], [0, 5, 50])\n",
      "[CpuDevice(id=0)]\n",
      "Fitting session NYU-305569f363-0934-464e-9a5b-77c8e67791a1...\n",
      "Session NYU-305569f363-0934-464e-9a5b-77c8e67791a1 completed.\n",
      "Time: 140.54040956497192\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" 'RUN CODE' \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\n",
    "prefix = '/home/ines/repositories/representation_learning_variability/'\n",
    "\n",
    "# Parameters\n",
    "n_jobs = 2  # Number of CPU cores to use\n",
    "\n",
    "# LOAD DATA\n",
    "data_path = prefix + 'paper-individuality/data/design_matrices/'\n",
    "all_files = os.listdir(data_path)\n",
    "design_matrices = [item for item in all_files if 'design_matrix' in item and 'standardized' not in item]\n",
    "idxs, mouse_names = idxs_from_files(design_matrices)\n",
    "\n",
    "var_interest = ['whisker_me']\n",
    "# var_interest = ['Lick count']\n",
    "\n",
    "\"\"\" GRID \"\"\"\n",
    "all_num_lags = [1, 3, 5, 7, 10, 15, 20, 30]\n",
    "all_num_lags=list(range(1, 20, 2))\n",
    "kappas=[0, 0.5, 1, 2, 3, 4, 5, 10, 20, 100]\n",
    "\n",
    "fixed_states = True\n",
    "num_states = 2\n",
    "\n",
    "if var_interest == ['whisker_me']:\n",
    "    n_jobs = 1\n",
    "    all_num_lags=[1, 10, 20, 40, 60] \n",
    "    all_num_lags=[1, 10, 20, 30] \n",
    "    # all_num_lags=list(range(1, 60, 10))\n",
    "    kappas=[0, 5, 50]\n",
    "    num_states = 2\n",
    "elif var_interest == ['Lick count']:\n",
    "    n_jobs = 3\n",
    "    kappas=[0, 1, 5, 10, 50, 100, 500, 1000]\n",
    "    num_states = 2\n",
    "\n",
    "params = num_states, all_num_lags, kappas\n",
    "\n",
    "\"\"\" FITTING PARAMETERS \"\"\"\n",
    "num_train_batches = 5\n",
    "method='prior'\n",
    "fit_method='em'\n",
    "zsc = True\n",
    "truncate = False\n",
    "\n",
    "if var_interest == ['whisker_me']:\n",
    "    zsc = True\n",
    "elif var_interest == ['Lick count']:\n",
    "    zsc = False\n",
    "\n",
    "fitting_params = str(num_train_batches)+'_'+method+'_'+fit_method+'_zsc_'+str(zsc)+'/'\n",
    "if truncate:\n",
    "    fitting_params = str(num_train_batches)+'_'+method+'_'+fit_method+'_zsc_'+str(zsc)+'_truncated/'\n",
    "\n",
    "save_path = prefix + 'paper-individuality/data/hmm/grid_search/'+fitting_params\n",
    "\n",
    "# # Run the grid search\n",
    "# run_grid_search_parallel(\n",
    "#     idxs, var_interest, zsc,\n",
    "#     fixed_states=fixed_states, truncate=truncate, params=params, sticky=False,\n",
    "#     save_path=save_path,  data_path=data_path, num_train_batches=num_train_batches, method=method, fit_method=fit_method, n_jobs=n_jobs)\n",
    "\n",
    "run_grid_search_serial(\n",
    "    idxs, var_interest, zsc,\n",
    "    fixed_states=fixed_states, truncate=truncate, params=params, sticky=False,\n",
    "    save_path=save_path,  data_path=data_path, num_train_batches=num_train_batches, method=method, fit_method=fit_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce543ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3f28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
